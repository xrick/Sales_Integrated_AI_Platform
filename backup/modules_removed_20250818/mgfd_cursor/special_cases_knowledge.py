#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MGFD ç‰¹æ®Šæ¡ˆä¾‹çŸ¥è­˜åº«æ¨¡çµ„
å¯¦ç¾åŸºæ–¼ç›¸ä¼¼åº¦åŒ¹é…çš„ç‰¹æ®Šæ¡ˆä¾‹è™•ç†ï¼Œé˜²æ­¢å¾ªç’°å’Œè™•ç†å›°é›£æ§½ä½æª¢æ¸¬
"""

import json
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from pathlib import Path
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from .similarity_engine import MGFDSimilarityEngine

class SpecialCasesKnowledgeBase:
    """ç‰¹æ®Šæ¡ˆä¾‹çŸ¥è­˜åº«é¡åˆ¥"""
    
    def __init__(self, knowledge_file_path: str = "libs/mgfd_cursor/humandata/special_cases_knowledge.json"):
        """
        åˆå§‹åŒ–ç‰¹æ®Šæ¡ˆä¾‹çŸ¥è­˜åº«
        
        Args:
            knowledge_file_path: çŸ¥è­˜åº«JSONæª”æ¡ˆè·¯å¾„
        """
        self.knowledge_file_path = Path(knowledge_file_path)
        self.knowledge_data = {}
        self.embedding_model = None
        self.cached_embeddings = {}
        self.loop_detection_history = {}
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–æ–°çš„ç›¸ä¼¼åº¦å¼•æ“
        self.similarity_engine = MGFDSimilarityEngine()
        
        # è¼‰å…¥çŸ¥è­˜åº«
        self._load_knowledge_base()
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self._initialize_embedding_model()
    
    def _load_knowledge_base(self):
        """è¼‰å…¥çŸ¥è­˜åº«æ•¸æ“š"""
        try:
            if self.knowledge_file_path.exists():
                with open(self.knowledge_file_path, 'r', encoding='utf-8') as f:
                    self.knowledge_data = json.load(f)
                self.logger.info(f"æˆåŠŸè¼‰å…¥çŸ¥è­˜åº«: {len(self.knowledge_data.get('categories', {}))} å€‹é¡åˆ¥")
            else:
                self.logger.warning(f"çŸ¥è­˜åº«æ–‡ä»¶ä¸å­˜åœ¨: {self.knowledge_file_path}")
                self.knowledge_data = {"categories": {}, "similarity_matching": {}, "loop_prevention": {}}
        except Exception as e:
            self.logger.error(f"è¼‰å…¥çŸ¥è­˜åº«å¤±æ•—: {e}")
            self.knowledge_data = {"categories": {}, "similarity_matching": {}, "loop_prevention": {}}
    
    def _initialize_embedding_model(self):
        """åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥æ¨¡å‹"""
        try:
            model_name = self.knowledge_data.get("similarity_matching", {}).get(
                "embedding_model", 
                "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            )
            self.embedding_model = SentenceTransformer(model_name)
            self.logger.info(f"æˆåŠŸåˆå§‹åŒ–åµŒå…¥æ¨¡å‹: {model_name}")
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–åµŒå…¥æ¨¡å‹å¤±æ•—: {e}")
            self.embedding_model = None
    
    def find_matching_case(self, query: str, session_id: str = None) -> Optional[Dict[str, Any]]:
        """
        å°‹æ‰¾åŒ¹é…çš„ç‰¹æ®Šæ¡ˆä¾‹
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢æ–‡æœ¬
            session_id: æœƒè©±IDï¼ˆç”¨æ–¼å¾ªç’°æª¢æ¸¬ï¼‰
            
        Returns:
            åŒ¹é…çš„æ¡ˆä¾‹è³‡è¨Šï¼Œå¦‚æœæ²’æœ‰åŒ¹é…å‰‡è¿”å›None
        """
        try:
            # æª¢æŸ¥æ˜¯å¦è™•æ–¼å¾ªç’°ç‹€æ…‹
            if session_id and self._is_in_loop(session_id, query):
                return self._get_loop_breaking_case(query)
            
            best_match = None
            best_similarity = 0.0
            primary_threshold = self.knowledge_data.get("similarity_matching", {}).get("primary_threshold", 0.75)
            
            # éæ­·æ‰€æœ‰é¡åˆ¥å°‹æ‰¾åŒ¹é…
            categories = self.knowledge_data.get("categories", {})
            for category_name, category_data in categories.items():
                cases = category_data.get("cases", [])
                
                for case in cases:
                    similarity = self._calculate_case_similarity(query, case)
                    
                    if similarity > best_similarity and similarity >= primary_threshold:
                        best_similarity = similarity
                        best_match = {
                            **case,
                            "matched_category": category_name,
                            "similarity_score": similarity
                        }
            
            # å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼Œè¨˜éŒ„ä½¿ç”¨çµ±è¨ˆ
            if best_match:
                self._record_case_usage(best_match)
                if session_id:
                    self._update_loop_detection_history(session_id, query, best_match)
            
            return best_match
            
        except Exception as e:
            self.logger.error(f"å°‹æ‰¾åŒ¹é…æ¡ˆä¾‹å¤±æ•—: {e}")
            return None
    
    def _calculate_case_similarity(self, query: str, case: Dict[str, Any]) -> float:
        """
        è¨ˆç®—æŸ¥è©¢èˆ‡æ¡ˆä¾‹çš„ç›¸ä¼¼åº¦
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            case: æ¡ˆä¾‹æ•¸æ“š
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•¸ (0-1)
        """
        try:
            # ä½¿ç”¨æ–°çš„ç›¸ä¼¼åº¦å¼•æ“
            comparison_texts = [case.get("customer_query", "")]
            comparison_texts.extend(case.get("query_variants", []))
            
            if not comparison_texts:
                return 0.0
            
            similarities = self.similarity_engine.calculate_similarity(query, comparison_texts)
            
            # æ ¹æ“šæ¬Šé‡è¨ˆç®—æœ€çµ‚ç›¸ä¼¼åº¦
            weights = self.knowledge_data.get("similarity_matching", {}).get("similarity_weights", {
                "main_query": 0.7, "variants": 0.3
            })
            
            main_similarity = similarities[0] if similarities else 0.0
            variant_similarities = similarities[1:] if len(similarities) > 1 else []
            
            final_similarity = (
                main_similarity * weights.get("main_query", 0.7) +
                (max(variant_similarities) if variant_similarities else 0.0) * weights.get("variants", 0.3)
            )
            
            # ç¢ºä¿è¿”å› Python native float é¡å‹
            return float(final_similarity)
            
        except Exception as e:
            self.logger.error(f"è¨ˆç®—ç›¸ä¼¼åº¦å¤±æ•—: {e}")
            return self._fallback_similarity_calculation(query, case)
    
    def _get_or_compute_embedding(self, text: str) -> np.ndarray:
        """ç²å–æˆ–è¨ˆç®—æ–‡æœ¬åµŒå…¥å‘é‡"""
        if text in self.cached_embeddings:
            return self.cached_embeddings[text]
        
        embedding = self.embedding_model.encode(text)
        self.cached_embeddings[text] = embedding
        return embedding
    
    def _fallback_similarity_calculation(self, query: str, case: Dict[str, Any]) -> float:
        """å‚™ç”¨ç›¸ä¼¼åº¦è¨ˆç®—ï¼ˆåŸºæ–¼é—œéµå­—åŒ¹é…ï¼‰"""
        try:
            query_lower = query.lower()
            comparison_texts = [case.get("customer_query", "")]
            comparison_texts.extend(case.get("query_variants", []))
            
            max_similarity = 0.0
            for text in comparison_texts:
                if not text:
                    continue
                
                text_lower = text.lower()
                # ç°¡å–®å­—ç¬¦åŒ¹é…
                common_chars = sum(1 for c in query_lower if c in text_lower)
                similarity = common_chars / max(len(query_lower), len(text_lower))
                max_similarity = max(max_similarity, similarity)
            
            return max_similarity
            
        except Exception as e:
            self.logger.error(f"å‚™ç”¨ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            return 0.0
    
    def _is_in_loop(self, session_id: str, query: str) -> bool:
        """æª¢æ¸¬æ˜¯å¦è™•æ–¼å¾ªç’°ç‹€æ…‹"""
        try:
            if session_id not in self.loop_detection_history:
                return False
            
            history = self.loop_detection_history[session_id]
            loop_config = self.knowledge_data.get("loop_prevention", {})
            
            max_repeats = loop_config.get("max_same_question_repeats", 2)
            detection_window = loop_config.get("loop_detection_window", 10)
            
            # æª¢æŸ¥æœ€è¿‘çš„æŸ¥è©¢æ­·å²
            recent_queries = history[-detection_window:] if len(history) >= detection_window else history
            
            # è¨ˆç®—ç›¸ä¼¼æŸ¥è©¢çš„æ•¸é‡
            similar_count = 0
            for historical_query in recent_queries:
                if self._queries_are_similar(query, historical_query.get("query", "")):
                    similar_count += 1
            
            return similar_count >= max_repeats
            
        except Exception as e:
            self.logger.error(f"å¾ªç’°æª¢æ¸¬å¤±æ•—: {e}")
            return False
    
    def _queries_are_similar(self, query1: str, query2: str, threshold: float = 0.8) -> bool:
        """åˆ¤æ–·å…©å€‹æŸ¥è©¢æ˜¯å¦ç›¸ä¼¼"""
        if not query1 or not query2:
            return False
        
        if self.embedding_model:
            try:
                emb1 = self._get_or_compute_embedding(query1)
                emb2 = self._get_or_compute_embedding(query2)
                similarity = float(cosine_similarity([emb1], [emb2])[0][0])
                return similarity >= threshold
            except:
                pass
        
        # å‚™ç”¨æ–¹æ³•ï¼šç°¡å–®å­—ç¬¦åŒ¹é…
        return query1.lower() == query2.lower()
    
    def _get_loop_breaking_case(self, query: str) -> Dict[str, Any]:
        """ç²å–æ‰“ç ´å¾ªç’°çš„ç‰¹æ®Šæ¡ˆä¾‹"""
        return {
            "case_id": "LOOP_BREAKER",
            "priority": "high",
            "customer_query": query,
            "detected_intent": {
                "primary_slot": "loop_detected",
                "confidence": 0.95,
                "reasoning": "æª¢æ¸¬åˆ°å¾ªç’°æ¨¡å¼ï¼Œå•Ÿå‹•å¾ªç’°æ‰“ç ´æ©Ÿåˆ¶"
            },
            "recommended_response": {
                "response_type": "loop_breaking_consultation",
                "message": "æˆ‘æ³¨æ„åˆ°æˆ‘å€‘å¯èƒ½åœ¨é‡è¤‡ç›¸åŒçš„å•é¡Œã€‚è®“æˆ‘æ›å€‹æ–¹å¼ä¾†å¹«åŠ©æ‚¨ï¼š",
                "funnel_question": {
                    "question_id": "loop_breaking_direct",
                    "question_text": "ç‚ºäº†æ›´ç›´æ¥åœ°å¹«åŠ©æ‚¨ï¼Œè«‹å‘Šè¨´æˆ‘æ‚¨çš„å…·é«”éœ€æ±‚ï¼š",
                    "options": [
                        {
                            "option_id": "direct_consultation",
                            "label": "ğŸ¯ ç›´æ¥æ¨è–¦",
                            "description": "æ ¹æ“šç›®å‰è³‡è¨Šç›´æ¥ç‚ºæ‚¨æ¨è–¦ç”¢å“",
                            "route": "direct_recommendation"
                        },
                        {
                            "option_id": "restart_consultation",
                            "label": "ğŸ”„ é‡æ–°é–‹å§‹",
                            "description": "é‡æ–°é–‹å§‹æ›´è©³ç´°çš„è«®è©¢éç¨‹",
                            "route": "restart_flow"
                        },
                        {
                            "option_id": "human_assistance",
                            "label": "ğŸ‘¤ äººå·¥å”åŠ©",
                            "description": "è½‰æ¥å°ˆæ¥­äººå“¡ç‚ºæ‚¨æœå‹™",
                            "route": "human_handoff"
                        }
                    ]
                }
            },
            "matched_category": "loop_prevention",
            "similarity_score": 1.0,
            "loop_breaking": True
        }
    
    def _update_loop_detection_history(self, session_id: str, query: str, matched_case: Dict[str, Any]):
        """æ›´æ–°å¾ªç’°æª¢æ¸¬æ­·å²"""
        if session_id not in self.loop_detection_history:
            self.loop_detection_history[session_id] = []
        
        history_entry = {
            "query": query,
            "matched_case_id": matched_case.get("case_id", ""),
            "timestamp": datetime.now().isoformat(),
            "similarity_score": matched_case.get("similarity_score", 0.0)
        }
        
        self.loop_detection_history[session_id].append(history_entry)
        
        # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœå…§
        max_history = 50
        if len(self.loop_detection_history[session_id]) > max_history:
            self.loop_detection_history[session_id] = self.loop_detection_history[session_id][-max_history:]
    
    def _record_case_usage(self, case: Dict[str, Any]):
        """è¨˜éŒ„æ¡ˆä¾‹ä½¿ç”¨çµ±è¨ˆ"""
        try:
            case_id = case.get("case_id", "")
            if not case_id:
                return
            
            # æ›´æ–°çŸ¥è­˜åº«ä¸­çš„ä½¿ç”¨çµ±è¨ˆ
            categories = self.knowledge_data.get("categories", {})
            for category_name, category_data in categories.items():
                cases = category_data.get("cases", [])
                for i, stored_case in enumerate(cases):
                    if stored_case.get("case_id") == case_id:
                        stored_case["usage_count"] = stored_case.get("usage_count", 0) + 1
                        stored_case["last_used"] = datetime.now().isoformat()
                        break
            
            # ä¿å­˜æ›´æ–°å¾Œçš„çŸ¥è­˜åº«
            self._save_knowledge_base()
            
        except Exception as e:
            self.logger.error(f"è¨˜éŒ„æ¡ˆä¾‹ä½¿ç”¨çµ±è¨ˆå¤±æ•—: {e}")
    
    def get_case_response(self, matched_case: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç²å–åŒ¹é…æ¡ˆä¾‹çš„æ¨è–¦å›æ‡‰
        
        Args:
            matched_case: åŒ¹é…çš„æ¡ˆä¾‹
            
        Returns:
            æ ¼å¼åŒ–çš„å›æ‡‰æ•¸æ“š
        """
        try:
            recommended_response = matched_case.get("recommended_response", {})
            
            # åŸºæœ¬å›æ‡‰çµæ§‹
            response = {
                "type": "special_case_response",
                "case_id": matched_case.get("case_id", ""),
                "matched_category": matched_case.get("matched_category", ""),
                "similarity_score": matched_case.get("similarity_score", 0.0),
                "message": recommended_response.get("message", ""),
                "response_type": recommended_response.get("response_type", ""),
                "confidence": matched_case.get("detected_intent", {}).get("confidence", 0.8),
                "timestamp": datetime.now().isoformat()
            }
            
            # æ·»åŠ æ¼æ–—å•é¡Œï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if "funnel_question" in recommended_response:
                response["funnel_question"] = recommended_response["funnel_question"]
            
            # æ·»åŠ æ¨è–¦çš„æ§½ä½å€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            detected_intent = matched_case.get("detected_intent", {})
            if "inferred_slots" in detected_intent:
                response["inferred_slots"] = detected_intent["inferred_slots"]
            
            # æ·»åŠ ç‰¹æ®Šè™•ç†æ¨™è¨˜
            if matched_case.get("loop_breaking", False):
                response["loop_breaking"] = True
            
            # æ·»åŠ å¾ŒçºŒå•é¡Œï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if "follow_up_questions" in recommended_response:
                response["follow_up_questions"] = recommended_response["follow_up_questions"]
            
            return response
            
        except Exception as e:
            self.logger.error(f"ç²å–æ¡ˆä¾‹å›æ‡‰å¤±æ•—: {e}")
            return {
                "type": "error",
                "message": "è™•ç†ç‰¹æ®Šæ¡ˆä¾‹æ™‚ç™¼ç”ŸéŒ¯èª¤",
                "confidence": 0.0
            }
    
    def add_new_case(self, category: str, case_data: Dict[str, Any]) -> bool:
        """
        æ·»åŠ æ–°çš„ç‰¹æ®Šæ¡ˆä¾‹
        
        Args:
            category: æ¡ˆä¾‹é¡åˆ¥
            case_data: æ¡ˆä¾‹æ•¸æ“š
            
        Returns:
            æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            categories = self.knowledge_data.get("categories", {})
            
            if category not in categories:
                categories[category] = {
                    "description": f"{category} æ¡ˆä¾‹",
                    "total_cases": 0,
                    "cases": []
                }
            
            # ç”Ÿæˆæ¡ˆä¾‹ID
            existing_cases = len(categories[category]["cases"])
            case_data["case_id"] = f"{category.upper()}_{existing_cases + 1:03d}"
            case_data["created_date"] = datetime.now().isoformat()
            case_data["usage_count"] = 0
            case_data["last_used"] = None
            
            # æ·»åŠ æ¡ˆä¾‹
            categories[category]["cases"].append(case_data)
            categories[category]["total_cases"] = len(categories[category]["cases"])
            
            # ä¿å­˜çŸ¥è­˜åº«
            self._save_knowledge_base()
            
            self.logger.info(f"æˆåŠŸæ·»åŠ æ–°æ¡ˆä¾‹: {case_data['case_id']}")
            return True
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ æ–°æ¡ˆä¾‹å¤±æ•—: {e}")
            return False
    
    def _save_knowledge_base(self):
        """ä¿å­˜çŸ¥è­˜åº«åˆ°æ–‡ä»¶"""
        try:
            # æ›´æ–°çµ±è¨ˆä¿¡æ¯
            self._update_statistics()
            
            with open(self.knowledge_file_path, 'w', encoding='utf-8') as f:
                json.dump(self.knowledge_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜çŸ¥è­˜åº«å¤±æ•—: {e}")
    
    def _update_statistics(self):
        """æ›´æ–°çŸ¥è­˜åº«çµ±è¨ˆä¿¡æ¯"""
        try:
            categories = self.knowledge_data.get("categories", {})
            total_cases = sum(len(cat.get("cases", [])) for cat in categories.values())
            
            # è¨ˆç®—ç¸½é«”æˆåŠŸç‡
            all_success_rates = []
            total_matches = 0
            
            for category_data in categories.values():
                for case in category_data.get("cases", []):
                    success_rate = case.get("success_rate", 0.0)
                    usage_count = case.get("usage_count", 0)
                    if usage_count > 0:
                        all_success_rates.append(success_rate)
                        total_matches += usage_count
            
            avg_success_rate = np.mean(all_success_rates) if all_success_rates else 0.0
            
            # æ›´æ–°çµ±è¨ˆä¿¡æ¯
            stats = self.knowledge_data.get("usage_statistics", {})
            stats.update({
                "total_cases": total_cases,
                "total_successful_matches": total_matches,
                "average_success_rate": round(avg_success_rate, 3),
                "last_statistics_update": datetime.now().isoformat()
            })
            
            self.knowledge_data["usage_statistics"] = stats
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°çµ±è¨ˆä¿¡æ¯å¤±æ•—: {e}")
    
    def get_knowledge_base_stats(self) -> Dict[str, Any]:
        """ç²å–çŸ¥è­˜åº«çµ±è¨ˆä¿¡æ¯"""
        return self.knowledge_data.get("usage_statistics", {})
    
    def clear_loop_history(self, session_id: str = None):
        """æ¸…é™¤å¾ªç’°æª¢æ¸¬æ­·å²"""
        if session_id:
            self.loop_detection_history.pop(session_id, None)
        else:
            self.loop_detection_history.clear()
        
        self.logger.info(f"æ¸…é™¤å¾ªç’°æ­·å²: {'æ‰€æœ‰æœƒè©±' if not session_id else session_id}")