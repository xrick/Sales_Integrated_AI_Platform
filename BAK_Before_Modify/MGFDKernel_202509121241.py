# BAK_Before_Modify/MGFDKernel_202509121241.py
# BAK_Before_Modify/MGFDKernel.py
# libs/MGFDKernel.py
"""
MGFD æ ¸å¿ƒæ§åˆ¶å™¨ - ç³»çµ±å¤§è…¦åŠå°å¤–å”¯ä¸€ä»‹é¢
è² è²¬å”èª¿äº”å¤§æ¨¡çµ„ï¼Œç®¡ç†å°è©±æµç¨‹ï¼Œè™•ç†å‰ç«¯è«‹æ±‚
å¾Œç«¯è™•ç†å®Œç•¢ï¼Œå›è¦†çµ¦å‰ç«¯çš„æ ¼å¼:
return {
        "success": True,
        "session_id": session_id,
        "message": "LLM Responses",
        "timestamp": datetime.now().isoformat()
        }
"""

import logging
import json
import redis
from typing import Dict, Any, Optional, List
import asyncio
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass

# å°å…¥å…¶ä»–æ¨¡çµ„ï¼ˆå¾…å¯¦ä½œï¼‰
# from .UserInputHandler import UserInputHandler
# from .StateManageHandler import StateManagementHandler
# from .PromptManagementHandler import PromptManagementHandler
# from .KnowledgeManageHandler import KnowledgeManagementHandler
# from .ResponseGenHandler import ResponseGenHandler
from .UserInputHandler.UserInputHandler import UserInputHandler
from .UserInputHandler import CheckUtils
from .StateManageHandler.StateManagementHandler import StateManagementHandler
from .PromptManagementHandler import prompt_manager
from .KnowledgeManageHandler.knowledge_manager import KnowledgeManager
from .ResponseGenHandler import ResponseGenHandler
from dataclasses import dataclass
from .RAG.LLM.LLMInitializer import LLMInitializer
from langchain.prompts import PromptTemplate
import re
logger = logging.getLogger(__name__)

###setup debug
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

@dataclass
class StateStatus:
    keyword_matched: str
    keyword_not_matched: str
    need_data_query:str
    no_data_query:str
    default:str

@dataclass
class States:
    OnInit: str
    OnReceiveMsg: str
    OnResponseMsg: str
    OnGenFunnelChat: str
    OnGenMDContent: str
    OnDataQuery: str
    OnQueriedDataProcessing: str
    OnSendFront: str
    OnWaitMsg: str


class MGFDKernel:
    """
    MGFD ç³»çµ±æ ¸å¿ƒæ§åˆ¶å™¨
    è·è²¬ï¼šå”èª¿äº”å¤§æ¨¡çµ„ï¼Œç®¡ç†å°è©±æµç¨‹ï¼Œè™•ç†å‰ç«¯è«‹æ±‚
    """
    def __init__(self, redis_client: Optional[redis.Redis] = None) -> None:
        """
        åˆå§‹åŒ– MGFD æ ¸å¿ƒæ§åˆ¶å™¨ 
        Args:
            redis_client: Redis å®¢æˆ¶ç«¯å¯¦ä¾‹ï¼Œç”¨æ–¼æœƒè©±ç‹€æ…‹æŒä¹…åŒ–
        """
        # åˆå§‹åŒ–çŸ¥è­˜ç®¡ç†å™¨ï¼ˆåŒ…å« LLM åŠŸèƒ½ï¼‰
        self.knowledge_manager = KnowledgeManager()
        self.redis_client = redis_client
        self.config = self._load_config()
        
        #self.slot_schema = self._load_slot_schema()
        
        # Initialize states and state_status before state_machine to avoid AttributeError
        self.states = States(
            OnInit="OnInit",
            OnReceiveMsg="OnReceiveMsg",
            OnResponseMsg="OnResponseMsg",
            OnGenFunnelChat="OnGenFunnelChat",
            OnGenMDContent="OnGenMDContent",
            OnDataQuery="OnDataQuery",
            OnQueriedDataProcessing="OnQueriedDataProcessing",
            OnSendFront="OnSendFront",
            OnWaitMsg="OnWaitMsg"
        )
        self.state_status = StateStatus(
            keyword_matched="keyword_matched",
            keyword_not_matched="keyword_not_matched",
            need_data_query="need_data_query",
            no_data_query="no_data_query",
            default="default"
        )
        
        # Load state machine after state_status is initialized
        self.state_machine = self._load_state_machine()
        # Welcome Prompt
        self.welcome_prompt = self._load_welcome_prompt()
        self.prompt_using = """
            èº«ç‚ºä¸€åå°ˆæ¥­ä¸”è¦ªåˆ‡çš„ç­†è¨˜å‹é›»è…¦éŠ·å”®å°ˆå®¶ï¼Œä½ çš„ä»»å‹™æ˜¯ä¸»å‹•è¿æ¥é€²å…¥è³£å ´çš„å®¢æˆ¶ï¼Œä¸¦å¼•å°ä»–å€‘å®Œæˆä¸€æ®µæ„‰å¿«ä¸”æœ‰æ•ˆç‡çš„è³¼ç‰©é«”é©—ã€‚
            ä½ çš„å°è©±æ‡‰éµå¾ªä»¥ä¸‹çµæ§‹èˆ‡åŸå‰‡ï¼š

            **1. ç†±æƒ…é–‹å ´èˆ‡åˆæ­¥æ¢ç´¢ï¼š**
            * ç”¨æº«æš–ä¸”é–‹æ”¾å¼çš„å•å€™é–‹å§‹å°è©±ï¼Œä¾‹å¦‚ï¼šã€Œæ‚¨å¥½ï¼Œæ­¡è¿å…‰è‡¨ï¼æƒ³æ‰¾ä¸€å°ä»€éº¼æ¨£çš„ç­†è¨˜å‹é›»è…¦å‘¢ï¼Ÿé‚„æ˜¯å…ˆéš¨æ„çœ‹çœ‹ï¼Ÿã€
            * é¿å…çµ¦äºˆå£“åŠ›ï¼Œè®“å®¢æˆ¶æ„Ÿåˆ°è¼•é¬†è‡ªåœ¨ã€‚

            **2. å¼•å°å¼éœ€æ±‚åˆ†æï¼ˆæ ¸å¿ƒä»»å‹™ï¼‰ï¼š**
            ä½ çš„ç›®æ¨™æ˜¯é€éç²¾æº–æå•ï¼Œåƒåµæ¢ä¸€æ¨£æ‹¼æ¹Šå‡ºå®¢æˆ¶çš„çœŸå¯¦éœ€æ±‚ã€‚è«‹ä¾åºè©¢å•ä»¥ä¸‹é—œéµå•é¡Œï¼Œä¸¦æ ¹æ“šå®¢æˆ¶çš„å›ç­”è¿½å•ç´°ç¯€ï¼š
            * **ä¸»è¦ç”¨é€”ï¼š** ã€Œè«‹å•æ‚¨è²·é€™å°é›»è…¦ï¼Œæœ€ä¸»è¦æ˜¯ç”¨ä¾†åšä»€éº¼å‘¢ï¼Ÿä¾‹å¦‚æ˜¯å·¥ä½œã€ä¸Šèª²ã€ç©éŠæˆ²ï¼Œé‚„æ˜¯å–®ç´”ä¸Šç¶²è¿½åŠ‡ï¼Ÿã€
            * **è»Ÿé«”èˆ‡å ´æ™¯ï¼š**
                * ï¼ˆå¦‚æœå·¥ä½œ/ä¸Šèª²ï¼‰ï¼šã€Œæœƒå¸¸ç”¨åˆ°å“ªäº›æ¯”è¼ƒç‰¹åˆ¥çš„è»Ÿé«”å—ï¼Ÿåƒæ˜¯å‰ªè¼¯å½±ç‰‡ã€å¯«ç¨‹å¼æˆ–è·‘æ•¸æ“šåˆ†æï¼Ÿã€
                * ï¼ˆå¦‚æœç©éŠæˆ²ï¼‰ï¼šã€Œå¹³å¸¸å–œæ­¡ç©å“ªä¸€ç¨®é¡å‹çš„éŠæˆ²å‘¢ï¼Ÿã€
            * **ä¾¿æ”œæ€§èˆ‡è¢å¹•ï¼š** ã€Œæœƒç¶“å¸¸éœ€è¦æŠŠå®ƒå¸¶å‡ºé–€å—ï¼Ÿå°æ–¼è¢å¹•å¤§å°æˆ–é‡é‡æœ‰æ²’æœ‰ç‰¹åˆ¥çš„åå¥½ï¼Ÿã€
            * **é ç®—ç¯„åœï¼š** ã€Œæ–¹ä¾¿è«‹å•ä¸€ä¸‹æ‚¨çš„é ç®—å¤§æ¦‚æ˜¯å¤šå°‘å‘¢ï¼Ÿæˆ‘èƒ½æ›´å¥½åœ°å¹«æ‚¨ç¯©é¸å‡ºCPå€¼æœ€é«˜çš„é¸æ“‡ã€‚ã€
            * **å“ç‰Œèˆ‡åå¥½ï¼š** ã€Œéå»æœ‰ç”¨éå“ªå€‹å“ç‰Œçš„é›»è…¦å—ï¼Ÿæœ‰æ²’æœ‰ç‰¹åˆ¥å–œæ­¡æˆ–ä¸å–œæ­¡çš„å“ç‰Œï¼Ÿã€
            * **é—œéµè€ƒé‡ï¼š** ã€Œå°æ‚¨ä¾†èªªï¼Œä¸€å°ç†æƒ³çš„ç­†é›»ï¼Œæœ€ä¸èƒ½å¦¥å”çš„åŠŸèƒ½æ˜¯ä»€éº¼ï¼Ÿæ˜¯æ•ˆèƒ½ã€é›»æ± çºŒèˆªåŠ›ï¼Œé‚„æ˜¯è¢å¹•çš„ç•«è³ªï¼Ÿã€

            **3. ç¢ºèªéœ€æ±‚èˆ‡æå‡ºæ–¹æ¡ˆï¼š**
            * åœ¨æå•å¾Œï¼Œç”¨ä¸€å¥è©±ç¸½çµä¸¦ç¢ºèªå®¢æˆ¶çš„éœ€æ±‚ã€‚ä¾‹å¦‚ï¼šã€Œå¥½çš„ï¼Œæ‰€ä»¥æˆ‘å¹«æ‚¨æ•´ç†ä¸€ä¸‹ï¼Œæ‚¨éœ€è¦ä¸€å°æ–¹ä¾¿æ”œå¸¶ã€çºŒèˆªåŠ›é•·ï¼Œä¸»è¦ç”¨ä¾†æ–‡æ›¸è™•ç†å’Œçœ‹å½±ç‰‡ï¼Œé ç®—åœ¨ä¸‰è¬å·¦å³çš„ç­†é›»ï¼Œå°å—ï¼Ÿã€
            * æ ¹æ“šç¢ºèªå¾Œçš„éœ€æ±‚ï¼Œæå‡º 2-3 æ¬¾æœ€ç¬¦åˆçš„ç­†é›»é¸é …ã€‚
            * ä»‹ç´¹æ¯æ¬¾ç­†é›»æ™‚ï¼Œä¸è¦åªè¬›è¦æ ¼ï¼Œè¦å¼·èª¿ã€Œå®ƒèƒ½ç‚ºå®¢æˆ¶å¸¶ä¾†çš„å¥½è™•ã€ã€‚ä¾‹å¦‚ï¼Œèˆ‡å…¶èªªã€Œå®ƒæœ‰16GB RAMã€ï¼Œä¸å¦‚èªªã€Œå®ƒæœ‰16GBçš„è¨˜æ†¶é«”ï¼Œæ‰€ä»¥æ‚¨åŒæ™‚é–‹å¾ˆå¤šç¶²é å’Œæ–‡ä»¶éƒ½ä¸æœƒå¡é “ï¼Œéå¸¸é †æš¢ã€‚ã€

            **4. è™•ç†ç–‘æ…®èˆ‡å®ŒæˆéŠ·å”®ï¼š**
            * è€å¿ƒå›ç­”å®¢æˆ¶å°æ¨è–¦ç”¢å“çš„ä»»ä½•å•é¡Œã€‚
            * å¦‚æœå®¢æˆ¶çŒ¶è±«ä¸æ±ºï¼Œå¯ä»¥ä¸»å‹•è©¢å•ï¼šã€Œé€™å¹¾æ¬¾æ‚¨æ¯”è¼ƒå–œæ­¡å“ªä¸€å°çš„è¨­è¨ˆå‘¢ï¼Ÿæˆ–æ˜¯æ‚¨é‚„åœ¨æ„å“ªå€‹éƒ¨åˆ†ï¼Œæˆ‘å†å¹«æ‚¨èªªæ˜ï¼Ÿã€
            * æœ€å¾Œï¼Œä»¥è¦ªåˆ‡çš„æ…‹åº¦å”åŠ©å®¢æˆ¶å®Œæˆè³¼è²·æµç¨‹æˆ–æä¾›å¾ŒçºŒè³‡è¨Šã€‚

            **äº’å‹•æº–å‰‡ï¼š**
            * **èªæ°£ï¼š** å§‹çµ‚ä¿æŒå°ˆæ¥­ã€å‹å–„ã€è€å¿ƒä¸”å……æ»¿ç†±å¿±ã€‚
            * **ç›®æ¨™ï¼š** ä½ çš„è§’è‰²æ˜¯ã€Œé¡§å•ã€ï¼Œä¸æ˜¯ã€Œæ¨éŠ·å“¡ã€ã€‚å°ˆæ³¨æ–¼è§£æ±ºå®¢æˆ¶çš„å•é¡Œï¼Œè€Œéåƒ…åƒ…è³£å‡ºæœ€è²´çš„å•†å“ã€‚
            * **é¿å…ï¼š** ä¸è¦ä½¿ç”¨éæ–¼æ·±å¥§çš„æŠ€è¡“è¡“èªï¼Œç›¡é‡ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»ä¾†è§£é‡‹ã€‚

            **åš´æ ¼éµå®ˆä½¿ç”¨å…§éƒ¨è³‡æ–™:**: è«‹çµ•å°å‹™å¿…åš´æ ¼éµå®ˆå…¬å¸ç”¢å“è³‡æ–™éƒ½å®Œå…¨ä¾†è‡ªå…¬å¸å…§éƒ¨æä¾›çš„å„ç¨®è³‡æ–™ï¼Œåš´æ ¼ç¦æ­¢å‡ºç¾ç«¶çˆ­å…¬å¸è³‡æ–™ã€‚

            **è³‡æ–™æ”¶é›†**:
            åœ¨ä½ å–å¾—ä»¥ä¸‹è³‡æ–™å‰ï¼Œå¯ä»¥ä¸æ–·é‡è¤‡è©¢å•ä½¿ç”¨è€…ï¼Œç›´åˆ°æ»¿è¶³è³‡æ–™æ”¶é›†å®Œæˆã€‚
            1. ç”¨é€”
            1. é ç®—
            2. cpuè¦æ ¼
            3. gpuè¦æ ¼
            4. ç­†é›»é‡é‡
            5. ssdå®¹é‡
            6. è¨˜æ†¶é«”å®¹é‡

        """
        # System-level prompt template (å„ªåŒ–ç‰ˆ - æ¸›å°‘ 70% Token æ¶ˆè€—)
        # æ³¨æ„ï¼šé€™æ˜¯ä¸å¯è®Šçš„æ¨¡æ¿ï¼Œé¿å…ç‹€æ…‹æ±¡æŸ“
        self.SysPromptTemplate = """ä½ æ˜¯å°ˆæ¥­çš„ç­†é›»éŠ·å”®é¡§å•ã€‚æ ¹æ“šä»¥ä¸‹ç”¢å“è³‡æ–™å›ç­”å®¢æˆ¶å•é¡Œï¼š

**ç”¢å“è³‡æ–™ï¼š**
{product_data}

**å®¢æˆ¶éœ€æ±‚ï¼š**
{user_query}

**å›æ‡‰è¦æ±‚ï¼š**
1. åƒ…ä½¿ç”¨æä¾›çš„ç”¢å“è³‡æ–™ï¼Œä¸å¾—ç·¨é€ 
2. æ¨è–¦ 2-3 æ¬¾æœ€ç¬¦åˆçš„ç”¢å“
3. ç”¨è¡¨æ ¼æ¯”è¼ƒä¸»è¦è¦æ ¼
4. ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œèªæ°£å°ˆæ¥­å‹å–„
5. ç„¡åˆé©ç”¢å“æ™‚å›è¦†ï¼šã€Œå»ºè­°è¯ç¹«å®¢æœå°ˆå®¶ç²å¾—å”åŠ©ã€

**è¼¸å‡ºæ ¼å¼ï¼š**
ç°¡æ½”çš„ Markdown æ ¼å¼ï¼ŒåŒ…å«ç”¢å“æ¨è–¦å’Œè¦æ ¼è¡¨æ ¼ã€‚"""
        # å®£å‘Šä¸‰å±¤å¼promptæ‰€éœ€è¦çš„è®Šæ•¸
        # self.product_data = None
        # self.prompt_using = None
        # self.answer = None
        # self.query = None
        # å®£å‘Šä¸‰å±¤å¼Prompt

        # åˆå§‹åŒ–äº”å¤§æ¨¡çµ„
        try:
            self.user_input_handler = UserInputHandler()
            self.prompt_manager = prompt_manager.get_global_prompt_manager()
            # knowledge_manager å·²ç¶“åœ¨ __init__ é–‹é ­åˆå§‹åŒ–äº†
            self.response_generator = ResponseGenHandler()
            self.state_manager = StateManagementHandler(redis_client)
            logger.info("æ‰€æœ‰æ¨¡çµ„åˆå§‹åŒ–æˆåŠŸ")
            self.slot_schema = self.user_input_handler.slot_schema
        except Exception as e:
            logger.error(f"æ¨¡çµ„åˆå§‹åŒ–å¤±æ•—: {e}")
            # å¦‚æœåˆå§‹åŒ–å¤±æ•—ï¼Œè¨­ç½®ç‚º None
            self.user_input_handler = None
            self.prompt_manager = None
            self.knowledge_manager = None
            self.response_generator = None
            self.state_manager = None
        
        # å˜—è©¦åˆå§‹åŒ– LLMï¼ˆæœ€å°è®Šæ›´ï¼›å¤±æ•—å‰‡ä¿æŒå›é€€æ©Ÿåˆ¶ï¼‰
        self.llm = None
        try:
            self.llm_initializer = LLMInitializer()
            self.llm = self.llm_initializer.get_llm()
            logger.info("LLM åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"LLM åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡ä½¿ç”¨å›é€€æ©Ÿåˆ¶: {e}")
            self.llm_initializer = None
            self.llm = None
        # è‹¥ Kernel å…§æœªå–å¾— LLMï¼Œä¸” KnowledgeManager å…§å·²æœ‰ llmï¼Œå¯ä½œè®€å–å¼å‚™æ´
        try:
            if self.llm is None and getattr(self, 'knowledge_manager', None) is not None:
                km_llm = getattr(self.knowledge_manager, 'llm', None)
                if km_llm is not None:
                    self.llm = km_llm
                    logger.info("æ¡ç”¨ KnowledgeManager ä¸­çš„ LLM ä½œç‚ºå‚™æ´")
        except Exception:
            # å®‰å…¨ä¿åº•ï¼Œä¸é˜»æ–·åˆå§‹åŒ–
            pass

        logger.info("MGFDKernel åˆå§‹åŒ–å®Œæˆ")
    
    def extract_markdown_tables(self, text: str) -> List[str]:
        """
        å¾æ–‡å­—ä¸­æå–æ‰€æœ‰ Markdown è¡¨æ ¼ï¼Œä¸¦ä»¥ list å½¢å¼å›å‚³ã€‚

        Args:
            text (str): è¼¸å…¥çš„å®Œæ•´æ–‡å­—

        Returns:
            List[str]: æ‰€æœ‰æ‰¾åˆ°çš„ Markdown è¡¨æ ¼ï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹å­—ä¸²
        """
        # ä½¿ç”¨ regex æ‰¾å‡º markdown è¡¨æ ¼
        table_pattern = re.compile(
            r"\|.*?\|\n\|[-:\s|]+\|\n(?:\|.*?\|\n?)+",
            re.DOTALL
        )
        tables = table_pattern.findall(text)
        return tables
    
    def _summarize_product_data(self, product_data: Dict[str, Any], max_products: int = 5) -> Dict[str, Any]:
        """
        æ‘˜è¦ç”¢å“æ•¸æ“šï¼Œåªä¿ç•™é—œéµè³‡è¨Šä»¥æ¸›å°‘ Token æ¶ˆè€—
        
        Args:
            product_data: åŸå§‹ç”¢å“æ•¸æ“š
            max_products: æœ€å¤§ç”¢å“æ•¸é‡
            
        Returns:
            æ‘˜è¦å¾Œçš„ç”¢å“æ•¸æ“š
        """
        if not isinstance(product_data, dict) or not product_data.get("products"):
            return product_data
            
        products = product_data.get("products", [])
        
        # é™åˆ¶ç”¢å“æ•¸é‡åˆ°æœ€ç›¸é—œçš„å¹¾å€‹
        products = products[:max_products]
        
        summarized_products = []
        for product in products:
            # åªä¿ç•™é—œéµè¦æ ¼ï¼Œå¤§å¹…æ¸›å°‘æ•¸æ“šé‡
            summarized_product = {
                "modeltype": product.get("modeltype", ""),
                "modelname": product.get("modelname", ""),
                "cpu_summary": self._extract_cpu_summary(product.get("cpu", "") or ""),
                "memory_summary": self._extract_memory_summary(product.get("memory", "") or ""),
                "lcd_summary": self._extract_lcd_summary(product.get("lcd", "") or ""),
                "battery_summary": self._extract_battery_summary(product.get("battery", "") or ""),
                "portability": self._assess_portability(product)
            }
            summarized_products.append(summarized_product)
        
        return {
            "query": product_data.get("query", ""),
            "status": product_data.get("status", ""),
            "count": len(summarized_products),
            "products": summarized_products,
            "note": f"å·²æ‘˜è¦ç‚º {len(summarized_products)} å€‹ä¸»è¦ç”¢å“è¦æ ¼"
        }
    
    def _extract_cpu_summary(self, cpu_text: str) -> str:
        """æå– CPU é—œéµè³‡è¨Š"""
        if not cpu_text:
            return "æœªæä¾› CPU è³‡è¨Š"
        
        # æå–ä¸»è¦ CPU å‹è™Ÿå’Œç³»åˆ—
        cpu_lines = cpu_text.split('\n')
        for line in cpu_lines:
            if any(keyword in line for keyword in ['Ryzen', 'AMD', 'Intel', 'Core']):
                return line.strip()[:100]  # é™åˆ¶é•·åº¦
        
        return cpu_text[:50] + "..." if len(cpu_text) > 50 else cpu_text
    
    def _extract_memory_summary(self, memory_text: str) -> str:
        """æå–è¨˜æ†¶é«”é—œéµè³‡è¨Š"""
        if not memory_text:
            return "æœªæä¾›è¨˜æ†¶é«”è³‡è¨Š"
        
        # å°‹æ‰¾è¨˜æ†¶é«”å®¹é‡å’Œé¡å‹
        import re
        ram_match = re.search(r'(\d+G[B]?|\d+GB|\d+TB)', memory_text)
        ddr_match = re.search(r'(DDR\d+|LPDDR\d+)', memory_text)
        
        summary_parts = []
        if ddr_match:
            summary_parts.append(ddr_match.group(1))
        if ram_match:
            summary_parts.append(f"æœ€é«˜ {ram_match.group(1)}")
        
        return " ".join(summary_parts) if summary_parts else memory_text[:50]
    
    def _extract_lcd_summary(self, lcd_text: str) -> str:
        """æå–è¢å¹•é—œéµè³‡è¨Š"""
        if not lcd_text:
            return "æœªæä¾›è¢å¹•è³‡è¨Š"
        
        # æå–è¢å¹•å°ºå¯¸å’Œè§£æåº¦
        import re
        size_match = re.search(r'(\d+\.?\d*)"', lcd_text)
        resolution_match = re.search(r'(\d+\*\d+|\d+x\d+)', lcd_text)
        
        summary_parts = []
        if size_match:
            summary_parts.append(f"{size_match.group(1)}å‹")
        if resolution_match:
            summary_parts.append(resolution_match.group(1))
        
        return " ".join(summary_parts) if summary_parts else lcd_text[:50]
    
    def _extract_battery_summary(self, battery_text: str) -> str:
        """æå–é›»æ± é—œéµè³‡è¨Š"""
        if not battery_text:
            return "æœªæä¾›é›»æ± è³‡è¨Š"
        
        # æå–é›»æ± å®¹é‡å’ŒçºŒèˆªåŠ›
        import re
        capacity_match = re.search(r'(\d+Wh)', battery_text)
        life_match = re.search(r'(\d+\s*[å°æ™‚|Hours|Hour])', battery_text)
        
        summary_parts = []
        if capacity_match:
            summary_parts.append(capacity_match.group(1))
        if life_match:
            summary_parts.append(f"çºŒèˆª {life_match.group(1)}")
        
        return " ".join(summary_parts) if summary_parts else "æ¨™æº–é›»æ± "
    
    def _assess_portability(self, product: Dict[str, Any]) -> str:
        """è©•ä¼°ä¾¿æ”œæ€§"""
        lcd = product.get("lcd", "") or ""  # ç¢ºä¿ä¸æ˜¯ None
        battery = product.get("battery", "") or ""  # ç¢ºä¿ä¸æ˜¯ None
        
        # ç°¡å–®çš„ä¾¿æ”œæ€§è©•ä¼°
        if any(size in lcd for size in ["11.6", "12", "13", "14"]):
            return "è¼•è–„ä¾¿æ”œ"
        elif any(size in lcd for size in ["15.6", "16"]):
            return "æ¨™æº–å°ºå¯¸"
        else:
            return "å°ºå¯¸æœªçŸ¥"
    
    # generate three-tier prompt
    def generate_three_tier_prompt(self,product_data=None, user_query=None):
        """ç”Ÿæˆä¸‰å±¤å¼æç¤º - ä¿®å¾©ç‰ˆï¼šé¿å…æ¨¡æ¿ç‹€æ…‹æ±¡æŸ“"""
        # ğŸ”§ ä¿®å¾©ï¼šæ¯æ¬¡éƒ½å¾ä¹¾æ·¨çš„æ¨¡æ¿é–‹å§‹ï¼Œé¿å…ç‹€æ…‹æ±¡æŸ“
        # ä½¿ç”¨ str.replace ä¾†é¿å… JSON ä¸­çš„ä½”ä½ç¬¦è¡çª
        result = self.SysPromptTemplate.replace("{product_data}", str(product_data))
        result = result.replace("{user_query}", str(user_query))
        return result
    #     """ç”Ÿæˆä¸‰å±¤å¼æç¤º"""
    #     return self.SysPrompt.format(product_data=None, prompt_using=self.prompt_using, 
    #                                  answer=self.answer, query=self.query)
    
    def _load_welcome_prompt(self) -> str:
        welcome_prompt = """
            è§’è‰²ï¼šèº«ç‚ºä¸€åå°ˆæ¥­ä¸”è¦ªåˆ‡çš„ç­†è¨˜å‹é›»è…¦éŠ·å”®å°ˆå®¶ï¼Œä½ çš„ä»»å‹™æ˜¯ä¸»å‹•è¿æ¥é€²å…¥è³£å ´çš„å®¢æˆ¶ï¼Œä¸¦å¼•å°ä»–å€‘å®Œæˆä¸€æ®µæ„‰å¿«ä¸”æœ‰æ•ˆç‡çš„è³¼ç‰©é«”é©—ã€‚
            åŸå‰‡ï¼š
                1.å¾ç¾åœ¨èµ·ï¼Œè«‹ä½ ä¸»å‹•æå‡ºå•é¡Œç›´åˆ°ä½ æœ‰è¶³å¤ è³‡è¨Šèƒ½å¤ å›ç­”å®¢æˆ¶çš„å•é¡Œã€‚
            ä»»å‹™ï¼š
            1. ç”¨æº«æš–ä¸”é–‹æ”¾å¼çš„å•å€™é–‹å§‹å°è©±ï¼Œä¾‹å¦‚ï¼šã€Œæ‚¨å¥½ï¼Œæ­¡è¿å…‰è‡¨ï¼æƒ³æ‰¾ä¸€å°ä»€éº¼æ¨£çš„ç­†è¨˜å‹é›»è…¦å‘¢ï¼Ÿé‚„æ˜¯å…ˆéš¨æ„çœ‹çœ‹ï¼Ÿã€
            2. é¿å…çµ¦äºˆå£“åŠ›ï¼Œè®“å®¢æˆ¶æ„Ÿåˆ°è¼•é¬†è‡ªåœ¨ã€‚
            3. é€éç²¾æº–æå•ï¼Œåƒåµæ¢ä¸€æ¨£æ‹¼æ¹Šå‡ºå®¢æˆ¶çš„çœŸå¯¦éœ€æ±‚ã€‚
            4. æ ¹æ“šå®¢æˆ¶çš„éœ€æ±‚ï¼Œæå‡º 2-3 æ¬¾æœ€ç¬¦åˆçš„ç­†é›»é¸é …ã€‚
        """
        return welcome_prompt
    


    def _load_config(self) -> Dict[str, Any]:
        """è¼‰å…¥ç³»çµ±é…ç½®"""
        try:
            config_path = Path(__file__).parent / "config" / "system_config.json"
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                # ä½¿ç”¨é è¨­é…ç½®
                return {
                    "max_session_duration": 3600,  # 1å°æ™‚
                    "max_slots_per_session": 20,
                    "default_response_timeout": 30,
                    "enable_streaming": True,
                    "log_level": "INFO"
                }
        except Exception as e:
            logger.error(f"è¼‰å…¥é…ç½®å¤±æ•—: {e}")
            return {}
    
    def _load_state_machine(self) -> Dict[str, Dict[str, Any]]:
        """è¼‰å…¥ç‹€æ…‹æ©Ÿå®šç¾©"""
        try:
            state_machine = {
                "OnInit": {
                    "description": "ç‹€æ…‹æ©Ÿåˆå§‹åŒ–ç‹€æ…‹",
                    "actions": ["GenerateWelcomePrompt"],
                    "next_states": {
                        self.state_status.keyword_matched: "OnResponseMsg",
                        self.state_status.keyword_not_matched: "OnGenFunnelChat"
                    }
                },
                "OnReceiveMsg": {
                    "description": "æ¥æ”¶ç”¨æˆ¶æ¶ˆæ¯ç‹€æ…‹",
                    "actions": [
                        "ExtractKeyword",
                        "CompareSentence"
                    ],
                    "next_states": {
                        self.state_status.keyword_matched: "OnResponseMsg",
                        self.state_status.keyword_not_matched: "OnGenFunnelChat"
                    }
                },
                "OnResponseMsg": {
                    "description": "å›æ‡‰æ¶ˆæ¯ç‹€æ…‹",
                    "actions": [
                        "DataQuery",
                        "GenerateMDContent"
                    ],
                    "next_states": {
                        self.state_status.need_data_query: "OnDataQuery",
                        self.state_status.no_data_query: "OnGenFunnelChat"
                    }
                },
                "OnGenFunnelChat": {
                    "description": "ç”Ÿæˆæ¼æ–—å¼èŠå¤©ç‹€æ…‹",
                    "actions": [
                        "Generate Messages to guide customers to our product"
                    ],
                    "next_states": {
                        self.state_status.default: "OnGenMDContent"
                    }
                },
                "OnGenMDContent": {
                    "description": "ç”Ÿæˆ Markdown å…§å®¹ç‹€æ…‹",
                    "actions": [
                        "GenerateMDContent"
                    ],
                    "next_states": {
                        self.state_status.default: "OnGenMDContent"
                    }
                },
                "OnDataQuery": {
                    "description": "åŸ·è¡Œå…§éƒ¨æ•¸æ“šæŸ¥è©¢ç‹€æ…‹",
                    "actions": [
                        "DataQuery"
                    ],
                    "next_states": {
                        self.state_status.default: "OnQueriedDataProcessing"
                    }
                },
                "OnQueriedDataProcessing": {
                    "description": "æŸ¥è©¢æ•¸æ“šå¾Œè™•ç†ç‹€æ…‹",
                    "actions": [
                        "DataPostprocessing"
                    ],
                    "next_states": {
                        self.state_status.default: "OnSendFront"
                    }
                },
                "OnSendFront": {
                    "description": "ç™¼é€æ•¸æ“šåˆ°å‰ç«¯ç‹€æ…‹",
                    "actions": [
                        "SendDataToFront"
                    ],
                    "next_states": {
                        self.state_status.default: "OnWaitMsg"
                    }
                },
                "OnWaitMsg": {
                    "description": "ç­‰å¾…ä¸‹ä¸€æ¢æ¶ˆæ¯ç‹€æ…‹",
                    "actions": [
                        "WaitNextMessage"
                    ],
                    "next_states": {
                        self.state_status.default: "OnReceiveMsg"
                    }
                }
            }
            logger.info(f"æˆåŠŸè¼‰å…¥ç‹€æ…‹æ©Ÿå®šç¾©ï¼ŒåŒ…å« {len(state_machine)} å€‹ç‹€æ…‹")
            return state_machine
        except Exception as e:
            logger.error(f"è¼‰å…¥ç‹€æ…‹æ©Ÿå®šç¾©å¤±æ•—: {e}")
            return {}
    
    async def process_message(
        self, 
        session_id: str, 
        message: str, 
        stream: bool = False
    ) -> Dict[str, Any]:
        """
        è™•ç†ç”¨æˆ¶æ¶ˆæ¯ - ä¸»è¦å…¥å£é»
        
        Args:
            session_id: æœƒè©±è­˜åˆ¥ç¢¼
            message: ç”¨æˆ¶è¼¸å…¥æ¶ˆæ¯
            stream: æ˜¯å¦ä½¿ç”¨ä¸²æµå›æ‡‰
            
        Returns:
            åŒ…å«å›æ‡‰å…§å®¹çš„å­—å…¸ï¼Œæ ¼å¼å°é½Š mgfd_ai.js æœŸæœ›
        """
        try:
            logger.info(f"è™•ç†æ¶ˆæ¯ - æœƒè©±: {session_id}, æ¶ˆæ¯: {message}...")
            
            # æª¢æŸ¥æ¨¡çµ„æ˜¯å¦å·²åˆå§‹åŒ–
            if not self._check_modules_initialized():
                return self._create_error_response("ç³»çµ±æ¨¡çµ„æœªåˆå§‹åŒ–")
            
            # è™•ç†æ¶ˆæ¯
            result = await self._process_message_internal(session_id, message)
            
            # æ·»åŠ æœƒè©±IDåˆ°å›æ‡‰
            result['session_id'] = session_id
            result['timestamp'] = datetime.now().isoformat()
            
            logger.info(f"æ¶ˆæ¯è™•ç†å®Œæˆ - æœƒè©±: {session_id}")
            return result
            
        except Exception as e:
            logger.error(f"è™•ç†æ¶ˆæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return self._create_error_response(f"ç³»çµ±å…§éƒ¨éŒ¯èª¤: {str(e)}")
    
    
    async def get_session_state(self, session_id: str) -> Dict[str, Any]:
        """
        ç²å–æœƒè©±ç‹€æ…‹
        
        Args:
            session_id: æœƒè©±è­˜åˆ¥ç¢¼
            
        Returns:
            æœƒè©±ç‹€æ…‹å­—å…¸
        """
        try:
            if not self.state_manager:
                return self._create_error_response("ç‹€æ…‹ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            
            # æš«æ™‚è¿”å›åŸºæœ¬ç‹€æ…‹ï¼Œå¾… StateManagementHandler å¯¦ä½œ
            return {
                "success": True,
                "session_id": session_id,
                "current_stage": "unknown",
                "filled_slots": {},
                "chat_history": [],
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ç²å–æœƒè©±ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return self._create_error_response(f"ç²å–æœƒè©±ç‹€æ…‹å¤±æ•—: {str(e)}")
    
    async def reset_session(self, session_id: str) -> Dict[str, Any]:
        """
        é‡ç½®æœƒè©±
        
        Args:
            session_id: æœƒè©±è­˜åˆ¥ç¢¼
            
        Returns:
            é‡ç½®çµæœå­—å…¸
        """
        try:
            logger.info(f"é‡ç½®æœƒè©±: {session_id}")
            
            if not self.state_manager:
                return self._create_error_response("ç‹€æ…‹ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            
            # æš«æ™‚è¿”å›æˆåŠŸï¼Œå¾… StateManagementHandler å¯¦ä½œ
            return {
                "success": True,
                "session_id": session_id,
                "message": "LLM Responses",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"é‡ç½®æœƒè©±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return self._create_error_response(f"é‡ç½®æœƒè©±å¤±æ•—: {str(e)}")
    
    async def get_system_status(self) -> Dict[str, Any]:
        """
        ç²å–ç³»çµ±ç‹€æ…‹
        
        Returns:
            ç³»çµ±ç‹€æ…‹å­—å…¸
        """
        try:
            modules_status = {
                "user_input_handler": self.user_input_handler is not None,
                "prompt_manager": self.prompt_manager is not None,
                "knowledge_manager": self.knowledge_manager is not None,
                "response_generator": self.response_generator is not None,
                "state_manager": self.state_manager is not None
            }
            
            redis_status = "connected" if self.redis_client and self.redis_client.ping() else "disconnected"
            
            return {
                "success": True,
                "system_status": {
                    "redis": redis_status,
                    "modules": modules_status,
                    "timestamp": datetime.now().isoformat(),
                    "version": "v2.0.0"
                }
            }
            
        except Exception as e:
            logger.error(f"ç²å–ç³»çµ±ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return self._create_error_response(f"ç²å–ç³»çµ±ç‹€æ…‹å¤±æ•—: {str(e)}")
    
    
    async def _process_message_internal(
        self, 
        session_id: str, 
        message: str #user input message
    ) -> Dict[str, Any]:
        """
        å…§éƒ¨æ¶ˆæ¯è™•ç†æµç¨‹
        """
        # Step 1: å»ºç«‹ context
        context = {
            "session_id": session_id,
            "user_message": message,
            "keyword": "nodata",
            "product_data": {},
            "timestamp": datetime.now().isoformat(),
            "state": self.states.OnReceiveMsg,
            "slots": {},
            "query_result": {},
            "previous_answer": str,
            "history": [],
            "control": {},
            "errors": [],
            "slot_schema": self.slot_schema,
            "config": self.config
        }
        
        # Step 2: è§£æè¼¸å…¥ï¼ˆUserInputHandlerï¼‰
        # é è¨­å€¼ï¼Œé¿å…å¾ŒçºŒ NameErrorï¼KeyError
        slot_metadata = {}
        _product_data = {}
        if self.user_input_handler:
            slot_name, slot_metadata = await self.user_input_handler.parse_keyword(message)
            logger.info(f"***************************slot_name START*********************************: \né—œéµè©:\n{slot_name}")
        if slot_name:
            context.setdefault("slots", {}).update({slot_name: slot_metadata})
        else:
            context.setdefault("slots", {}).update({"": {}})
        
        # Step 3: ç‹€æ…‹æ©Ÿé©…å‹•ï¼ˆStateManagerï¼‰
        if slot_metadata.get("ifDBSearch", True):
            context["state"] = self.states.OnDataQuery#"OnDataQuery"#
        else:
            context["state"] = self.states.OnGenFunnelChat#"OnGenFunnelChat"
        self.query = message

        # Step 4: çŸ¥è­˜æŸ¥è©¢ï¼ˆå¦‚éœ€è¦ï¼‰
        #éœ€è¦åŠ å…¥knowledge_manager.search(context)
        #è‹¥ifDBSearchç‚ºTrueï¼Œå‰‡é€²è¡ŒçŸ¥è­˜æŸ¥è©¢ï¼Œä¸¦å°‡çµæœå­˜å…¥context["query_result"],
        #é€™æ˜¯product_data
        if slot_metadata.get("ifDBSearch", True):
            # ç›´æ¥é€²è¡Œèˆ‡é—œéµå­—ç›¸é—œçš„ç”¢å“è¦æ ¼æœå°‹ï¼ˆä»¥éé˜»å¡æ–¹å¼åœ¨åŸ·è¡Œç·’æ± åŸ·è¡Œï¼‰
            _product_data = await asyncio.to_thread(self.knowledge_manager.search_product_data, message)
            context['keyword'] = slot_name
            logging.info(f"çŸ¥è­˜æŸ¥è©¢çµæœ: {_product_data}")
            #é€²è¡Œ
        #step 5: generate three-tier prompt and send prompt to LLM
        # æ‘˜è¦ç”¢å“æ•¸æ“šä»¥å¤§å¹…æ¸›å°‘ Token æ¶ˆè€—
        if _product_data and isinstance(_product_data, dict) and _product_data.get("products"):
            logger.info(f"åŸå§‹ç”¢å“æ•¸æ“šåŒ…å« {len(_product_data.get('products', []))} å€‹ç”¢å“")
            _product_data = self._summarize_product_data(_product_data, max_products=3)
            logger.info(f"æ‘˜è¦å¾Œç”¢å“æ•¸æ“šåŒ…å« {len(_product_data.get('products', []))} å€‹ç”¢å“")
        
        # å°‡ product_data è½‰ç‚º JSON å­—ä¸²æ³¨å…¥ï¼Œé™ä½æ¨¡å‹èª¤åˆ¤çµæ§‹æ©Ÿç‡
        product_data_json = json.dumps(_product_data, ensure_ascii=False, indent=2)
        logger.info(f"ç”¢å“è³‡æ–™ JSON é•·åº¦: {len(product_data_json)} (å·²å„ªåŒ–)")
        logger.info(f"***************************ç”¢å“è³‡æ–™START*********************************: \nç”¢å“è³‡æ–™:\n{product_data_json}")
        logger.info(f"***************************ç”¢å“è³‡æ–™END***********************************\n")

        # ğŸ”§ ä¿®å¾©ï¼šä½¿ç”¨å±€éƒ¨è®Šé‡é¿å…ç‹€æ…‹æ±¡æŸ“
        current_prompt = self.generate_three_tier_prompt(product_data=product_data_json, user_query=self.query)
        logger.info(f"***************************ç³»çµ±æç¤ºSTART********************************** \n{current_prompt}")
        logger.info(f"***************************ç³»çµ±æç¤ºEND***********************************\n")
        #_product_data
        # # å°‡ä½¿ç”¨è€…æŸ¥è©¢åŒæ™‚æä¾›ç‚º user_queryï¼Œé¿å…æ¨¡æ¿éµåä¸ä¸€è‡´å°è‡´ KeyError
        # 
        # self.SysPrompt = PromptTemplate(input_variables=["product_data", "user_query"], template=self.SysPrompt)
        # chain = self.SysPrompt | self.llm
        
        context['query_result'] = {"qry_result": _product_data}
        context['keyword'] = slot_name
        logging.info(f"product_data: {context['query_result']}")
        
        # Step 6: ç”Ÿæˆå›æ‡‰ï¼ˆResponseGeneratorï¼‰
        # è‹¥æŸ¥ç„¡ç”¢å“ï¼Œç›´æ¥å›è¦†æŒ‡å®šæç¤ºå¥ï¼›å¦å‰‡å°‡ System Prompt ç™¼é€çµ¦ LLM
        llm_output = None
        try:
            no_products = (
                isinstance(_product_data, dict)
                and (
                    _product_data.get("status") in {"no_results", "no_spec_data", "no_database", "error"}
                    or not _product_data.get("products")
                )
            )
            # tables = []
            if no_products:
                llm_output = "ç›®å‰å°šæœªæœå°‹åˆ°ç¬¦æ‚¨éœ€æ±‚çš„ç”¢å“ï¼Œæ˜¯å¦é€²è¡Œä¸åŒè¦æ ¼ç”¢å“çš„æœå°‹å‘¢ï¼Ÿ"
            else:
                if hasattr(self, 'llm') and self.llm:
                    try:
                        # ä½¿ç”¨ asyncio.wait_for æä¾›é¡å¤–çš„è¶…æ™‚ä¿è­·ï¼ˆ90ç§’ï¼Œç¨å¤§æ–¼ LLM çš„ request_timeoutï¼‰
                        llm_output = await asyncio.wait_for(
                            asyncio.to_thread(self.llm.invoke, current_prompt),
                            timeout=90
                        )
                        ## format markdown tables
                        # tables = self.extract_markdown_tables(llm_output)
                        # if tables:
                        #     for table in tables:
                        #         llm_output = llm_output.replace(table, f"```markdown\n{table}\n```")
                        ## end of format markdown tables
                        if isinstance(llm_output, dict):
                            llm_output = llm_output.get('content') or json.dumps(llm_output, ensure_ascii=False)
                        if llm_output is not None and not isinstance(llm_output, str):
                            llm_output = str(llm_output)
                        logger.info(f"LLM ç”ŸæˆæˆåŠŸï¼Œé•·åº¦: {len(llm_output) if llm_output else 0}")
                    except asyncio.TimeoutError:
                        logger.error("LLM èª¿ç”¨è¶…æ™‚ (90ç§’)ï¼Œå›é€€è‡³ç°¡åŒ–å›æ‡‰")
                        llm_output = "æŠ±æ­‰ï¼Œç³»çµ±è™•ç†æ™‚é–“è¼ƒé•·ï¼Œæˆ‘ç‚ºæ‚¨æä¾›ç°¡åŒ–çš„ç”¢å“å»ºè­°ã€‚æ ¹æ“šæ‚¨çš„éœ€æ±‚ã€Œè¼•ä¾¿å®¹æ˜“æ”œå¸¶ã€ï¼Œæˆ‘æ¨è–¦ä»¥ä¸‹è¼•è–„ç­†é›»é¡å‹ï¼Œè©³ç´°è¦æ ¼è«‹è¯ç¹«å®¢æœå°ˆå®¶ç²å¾—å”åŠ©ã€‚"
                    except Exception as e:
                        logger.error(f"LLM èª¿ç”¨ç™¼ç”Ÿç•°å¸¸: {e}")
                        llm_output = "ç³»çµ±æš«æ™‚ç„¡æ³•ç”Ÿæˆè©³ç´°å›æ‡‰ï¼Œå»ºè­°è¯ç¹«å®¢æœå°ˆå®¶ä»¥ç²å¾—ç”¢å“æ¨è–¦ã€‚"
                else:
                    logger.info("LLM æœªåˆå§‹åŒ–ï¼Œè·³éç”Ÿæˆæ­¥é©Ÿï¼Œå›é€€è‡³è³‡æ–™å­—ä¸²")
        except Exception as e:
            logger.warning(f"LLM ç”Ÿæˆå¤±æ•—ï¼Œå›é€€è‡³æŸ¥è©¢è³‡æ–™: {e}")

        # step 7: format frontend response
        # presentation_data_prompt = """
        # *æ¡ç”¨markdownæ ¼å¼è¼¸å‡ºï¼šè«‹markdown syntaxç”¢ç”Ÿå°ˆæ¥­ã€ç°¡æ½”ã€ç¾è§€çš„å ±å‘Šï¼Œè®“ä½¿ç”¨è€…èƒ½å¤ æ¸…æ¥šäº†è§£ã€‚
        # {product_data}
        # """.format(product_data=product_data_json)
        # è‹¥æœ‰ llm_output å‰‡å„ªå…ˆä½¿ç”¨ï¼Œå¦å‰‡å›å‚³æŸ¥è©¢è³‡æ–™å­—ä¸²ï¼Œé¿å…å‰ç«¯é¡¯ç¤º [object Object]
        
        response_result = {
            "type": "general",
            "message": llm_output,
            "success": True
        }
        # # è‹¥æœ‰ llm_output å‰‡å„ªå…ˆä½¿ç”¨ï¼Œå¦å‰‡å›å‚³æŸ¥è©¢è³‡æ–™å­—ä¸²ï¼Œé¿å…å‰ç«¯é¡¯ç¤º [object Object]
        # response_result = {
        #     "type": "general",
        #     "message": llm_output if llm_output else json.dumps(_product_data, ensure_ascii=False, indent=2),
        #     "success": True
        # }
        return response_result
        # if self.response_generator:
        #     response_result = await self.response_generator.generate(context)
        #     context.update(response_result)
            
        #     # æ˜ å°„ ResponseGenHandler çš„å­—æ®µåˆ° _format_frontend_response æœŸå¾…çš„å­—æ®µ
        #     if response_result.get("type") == "funnel_question":
        #         context["current_question"] = response_result.get("current_question")
        #         context["question_options"] = response_result.get("question_options", [])
        #         context["question_message"] = response_result.get("message", "")
        # else:
        #     context.update({
        #         "response_type": "general",
        #         "message": "å›æ‡‰ç”Ÿæˆå™¨æœªåˆå§‹åŒ–"
        #     })
        
        # result = self._format_frontend_response(context)
        # logger.info(f"ğŸ”§ æœ€çµ‚å›æ‡‰çµæœ: {result}")
        # return result
    
    # async def _process_message_internal(
    #     self, 
    #     session_id: str, 
    #     message: str
    # ) -> Dict[str, Any]:
    #     """
    #     å…§éƒ¨æ¶ˆæ¯è™•ç†æµç¨‹
        
    #     Args:
    #         session_id: æœƒè©±è­˜åˆ¥ç¢¼
    #         message: ç”¨æˆ¶è¼¸å…¥æ¶ˆæ¯
            
    #     Returns:
    #         è™•ç†çµæœå­—å…¸
    #     """
    #     # Step 1: å»ºç«‹ context
    #     context = await self._build_context(session_id, message)
        
    #     # Step 2: è§£æè¼¸å…¥ï¼ˆUserInputHandlerï¼‰
    #     if self.user_input_handler:
    #         input_result = await self.user_input_handler.parse(message, context)
    #         context.update(input_result)
    #     else:
    #         # æš«æ™‚ä½¿ç”¨åŸºæœ¬è§£æ
    #         context.update({
    #             "intent": "unknown",
    #             "slots_update": {},
    #             "control": {},
    #             "errors": [],
    #             "confidence": 0.0
    #         })
        
    #     # Step 3: ç‹€æ…‹æ©Ÿé©…å‹•ï¼ˆStateManagerï¼‰
    #     if self.state_manager:
    #         state_result = await self.state_manager.process_state(context)
    #         context.update(state_result)
    #     else:
    #         # æš«æ™‚ä½¿ç”¨åŸºæœ¬ç‹€æ…‹è™•ç†
    #         context.update({
    #             "stage": "INIT",
    #             "needs_knowledge_search": False
    #         })
        
    #     # Step 4: çŸ¥è­˜æŸ¥è©¢ï¼ˆå¦‚éœ€è¦ï¼‰
    #     if context.get('needs_knowledge_search') and self.knowledge_manager:
    #         knowledge_result = await self.knowledge_manager.search(context)
    #         context.update(knowledge_result)
        
    #     # Step 5: ç”Ÿæˆå›æ‡‰ï¼ˆResponseGeneratorï¼‰
    #     if self.response_generator:
    #         response_result = await self.response_generator.generate(context)
    #         context.update(response_result)
    #     else:
    #         # æš«æ™‚ä½¿ç”¨åŸºæœ¬å›æ‡‰
    #         context.update({
    #             "response_type": "general",
    #             "response_message": "ç³»çµ±æ­£åœ¨è™•ç†æ‚¨çš„è«‹æ±‚..."
    #         })
        
    #     # Step 6: æ›´æ–°ç‹€æ…‹
    #     if self.state_manager:
    #         await self.state_manager.update_session_state(session_id, context)
        
    #     return self._format_frontend_response(context)
    
    # async def _build_context(
    #     self, 
    #     session_id: str, 
    #     message: str
    # ) -> Dict[str, Any]:
    #     """
    #     å»ºç«‹è™•ç†ä¸Šä¸‹æ–‡
        
    #     Args:
    #         session_id: æœƒè©±è­˜åˆ¥ç¢¼
    #         message: ç”¨æˆ¶è¼¸å…¥æ¶ˆæ¯
            
    #     Returns:
    #         ä¸Šä¸‹æ–‡å­—å…¸
    #     """
    #     # ç²å–ç¾æœ‰æœƒè©±ç‹€æ…‹
    #     session_state = {}
    #     if self.state_manager:
    #         session_state = await self.state_manager.get_session_state(session_id) or {}
        
    #     # æ ¹æ“šæ¶ˆæ¯å…§å®¹ç¢ºå®šç‹€æ…‹
    #     if message and message.strip():
    #         current_state = "OnReceiveMsg"
    #     else:
    #         current_state = session_state.get("state", "OnWaitMsg")
        
    #     context = {
    #         "session_id": session_id,
    #         "user_message": message,
    #         "timestamp": datetime.now().isoformat(),
    #         "state": current_state,
    #         "slots": session_state.get("slots", {}),
    #         "history": session_state.get("history", []),
    #         "control": {},
    #         "errors": [],
    #         "slot_schema": self.slot_schema,
    #         "config": self.config
    #     }
        
    #     return context
    
    def _format_frontend_response(
        self, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–å‰ç«¯å›æ‡‰
        
        Args:
            context: è™•ç†ä¸Šä¸‹æ–‡
            
        Returns:
            æ ¼å¼åŒ–å¾Œçš„å›æ‡‰å­—å…¸
        """
        state = context.get('state', 'unknown')
        response_type = context.get('response_type', 'general')
        
        # æ ¹æ“šç‹€æ…‹å’Œå›æ‡‰é¡å‹æ ¼å¼åŒ–
        if state == 'OnReceiveMsg':
            return {
                "success": True,
                "type": "funnel_start",
                "message": context.get('funnel_intro', 'æ­¡è¿ä½¿ç”¨ç­†é›»è³¼ç‰©åŠ©æ‰‹ï¼'),
                "session_id": context.get('session_id')
            }
        elif state == 'OnGenFunnelChat':
            return {
                "success": True,
                "type": "funnel_question",
                "question": {
                    "question_text": context.get('current_question'),
                    "options": context.get('question_options', [])
                },
                "session_id": context.get('session_id'),
                "message": context.get('question_message', '')
            }
        elif state == 'OnResponseMsg':
            return {
                "success": True,
                "type": "recommendation",
                "recommendations": context.get('recommendations', []),
                "comparison_table": context.get('comparison_table'),
                "summary": context.get('recommendation_summary'),
                "session_id": context.get('session_id')
            }
        elif state == 'OnGenMDContent':
            return {
                "success": True,
                "type": "elicitation",
                "message": context.get('elicitation_message'),
                "slots_needed": context.get('slots_needed', []),
                "session_id": context.get('session_id')
            }
        else:
            # ç›´æ¥è¿”å›çµæ§‹åŒ–æ ¼å¼ï¼Œä¸è¦åŒ…è£æˆ stream_response
            return {
                "success": True,
                "type": "general",
                "message": context.get('message') or context.get('response_message', ''),
                "session_id": context.get('session_id')
            }
    
    def _check_modules_initialized(self) -> bool:
        """æª¢æŸ¥æ¨¡çµ„æ˜¯å¦å·²åˆå§‹åŒ–"""
        # åªéœ€è¦ UserInputHandler å·²åˆå§‹åŒ–å³å¯é€²è¡ŒåŸºæœ¬è™•ç†
        return self.user_input_handler is not None
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """å‰µå»ºéŒ¯èª¤å›æ‡‰"""
        return {
            "success": False,
            "error": error_message,
            "timestamp": datetime.now().isoformat()
        }
    
    def set_user_input_handler(self, handler):
        """è¨­ç½®ç”¨æˆ¶è¼¸å…¥è™•ç†å™¨"""
        self.user_input_handler = handler
        logger.info("UserInputHandler å·²è¨­ç½®")
    
    def set_prompt_manager(self, manager):
        """è¨­ç½®æç¤ºç®¡ç†å™¨"""
        self.prompt_manager = manager
        logger.info("PromptManagementHandler å·²è¨­ç½®")
    
    def set_knowledge_manager(self, manager):
        """è¨­ç½®çŸ¥è­˜ç®¡ç†å™¨"""
        self.knowledge_manager = manager
        logger.info("KnowledgeManagementHandler å·²è¨­ç½®")
    
    def set_response_generator(self, generator):
        """è¨­ç½®å›æ‡‰ç”Ÿæˆå™¨"""
        self.response_generator = generator
        logger.info("ResponseGenHandler å·²è¨­ç½®")
    
    def set_state_manager(self, manager):
        """è¨­ç½®ç‹€æ…‹ç®¡ç†å™¨"""
        self.state_manager = manager
        logger.info("StateManagementHandler å·²è¨­ç½®")
