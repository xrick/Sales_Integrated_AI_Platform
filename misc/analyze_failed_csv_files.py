#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æå¤±æ•—çš„CSVæª”æ¡ˆ
"""

import pandas as pd
import sys
from pathlib import Path

# æ·»åŠ libsç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent / 'libs'))

def analyze_failed_csv_files():
    """åˆ†æå¤±æ•—çš„CSVæª”æ¡ˆ"""
    print("=== åˆ†æå¤±æ•—çš„CSVæª”æ¡ˆ ===\n")
    
    # å¤±æ•—çš„æª”æ¡ˆåˆ—è¡¨
    failed_files = [
        "17_result.csv",
        "AC01_result.csv", 
        "27_result.csv",
        "728_result.csv",
        "960_result.csv",
        "656_result.csv",
        "326_result.csv",
        "835_result.csv"
    ]
    
    csv_dir = Path("data/raw/EM_New TTL_241104_AllTransformedToGoogleSheet")
    
    for csv_file in failed_files:
        file_path = csv_dir / csv_file
        print(f"--- åˆ†ææª”æ¡ˆ: {csv_file} ---")
        
        if not file_path.exists():
            print(f"   âŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
            continue
            
        try:
            # è®€å–CSVæª”æ¡ˆ
            df = pd.read_csv(file_path)
            print(f"   ğŸ“Š æª”æ¡ˆå¤§å°: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_cols = ['modeltype', 'modelname']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                print(f"   âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}")
                continue
            
            # æª¢æŸ¥ç¬¬ä¸€è¡Œæ•¸æ“š
            first_row = df.iloc[0]
            print(f"   ğŸ“‹ ç¬¬ä¸€è¡Œæ•¸æ“š:")
            print(f"      modeltype: '{first_row.get('modeltype', 'N/A')}'")
            print(f"      modelname: '{first_row.get('modelname', 'N/A')}'")
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºå…¬å¸ç”¢å“
            modelname = str(first_row.get('modelname', ''))
            modeltype = str(first_row.get('modeltype', ''))
            
            # æ¸…ç†å‰ç¶´
            if 'Model Name:' in modelname:
                modelname = modelname.replace('Model Name:', '').strip()
            if 'Version:' in modeltype:
                modeltype = modeltype.replace('Version:', '').strip()
            
            print(f"   ğŸ”§ æ¸…ç†å¾Œ:")
            print(f"      modeltype: '{modeltype}'")
            print(f"      modelname: '{modelname}'")
            
            # æª¢æŸ¥å…¬å¸ç”¢å“é©—è­‰
            from mgfd_cursor.knowledge_base import NotebookKnowledgeBase
            kb = NotebookKnowledgeBase()
            
            # æ¨¡æ“¬é©—è­‰éç¨‹
            is_company_product = kb._is_company_product(modelname)
            is_valid_modeltype = kb._is_valid_modeltype(modeltype)
            
            print(f"   âœ… é©—è­‰çµæœ:")
            print(f"      å…¬å¸ç”¢å“: {is_company_product}")
            print(f"      æœ‰æ•ˆå‹è™Ÿ: {is_valid_modeltype}")
            
            if not is_company_product:
                print(f"   âŒ å¤±æ•—åŸå› : ä¸æ˜¯å…¬å¸ç”¢å“ (modelname: {modelname})")
            elif not is_valid_modeltype:
                print(f"   âŒ å¤±æ•—åŸå› : ç„¡æ•ˆå‹è™Ÿæ ¼å¼ (modeltype: {modeltype})")
            else:
                print(f"   âœ… é©—è­‰é€šé")
            
            print()
            
        except Exception as e:
            print(f"   âŒ è®€å–æª”æ¡ˆå¤±æ•—: {e}")
            print()

if __name__ == "__main__":
    analyze_failed_csv_files()
