#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦æ•´åˆå¾Œçš„default_slots.json
"""

import json
import sys
from pathlib import Path

def test_integration_completeness():
    """æ¸¬è©¦æ•´åˆå®Œæ•´æ€§"""
    print("=== æ¸¬è©¦æ•´åˆå®Œæ•´æ€§ ===\n")
    
    try:
        # è¼‰å…¥æ•´åˆå¾Œçš„æª”æ¡ˆ
        default_slots_path = Path(__file__).parent / "libs" / "mgfd_cursor" / "humandata" / "default_slots.json"
        
        with open(default_slots_path, 'r', encoding='utf-8') as f:
            default_slots = json.load(f)
        
        print("âœ… æˆåŠŸè¼‰å…¥æ•´åˆå¾Œçš„default_slots.json")
        
        # æª¢æŸ¥ç‰ˆæœ¬ä¿¡æ¯
        metadata = default_slots["metadata"]
        print(f"ğŸ“‹ ç‰ˆæœ¬ä¿¡æ¯:")
        print(f"   ç‰ˆæœ¬: {metadata['version']}")
        print(f"   æè¿°: {metadata['description']}")
        print(f"   æ•´åˆä¿¡æ¯: {metadata['integration_info']}")
        
        # æª¢æŸ¥åŠŸèƒ½ç‰¹æ€§
        features = metadata["features"]
        print(f"\nğŸ”§ åŠŸèƒ½ç‰¹æ€§:")
        for feature, enabled in features.items():
            status = "âœ…" if enabled else "âŒ"
            print(f"   {status} {feature}")
        
        # æª¢æŸ¥æ§½ä½åŒç¾©è©å®Œæ•´æ€§
        slot_definitions = default_slots["slot_definitions"]
        print(f"\nğŸ” æª¢æŸ¥æ§½ä½åŒç¾©è©å®Œæ•´æ€§...")
        
        slots_with_synonyms = 0
        total_slots = len(slot_definitions)
        
        for slot_name, slot_def in slot_definitions.items():
            if "synonyms" in slot_def:
                synonyms = slot_def["synonyms"]
                print(f"   âœ… {slot_name}: åŒ…å«åŒç¾©è© ({len(synonyms)} å€‹å€¼)")
                
                # æª¢æŸ¥æ¯å€‹å€¼çš„åŒç¾©è©çµæ§‹
                for value_name, value_synonyms in synonyms.items():
                    if all(key in value_synonyms for key in ["keywords", "regex", "semantic"]):
                        print(f"      âœ… {value_name}: å®Œæ•´çµæ§‹")
                    else:
                        print(f"      âš ï¸  {value_name}: çµæ§‹ä¸å®Œæ•´")
                
                slots_with_synonyms += 1
            else:
                print(f"   âŒ {slot_name}: ç¼ºå°‘åŒç¾©è©")
        
        print(f"\nğŸ“Š åŒç¾©è©è¦†è“‹ç‡: {slots_with_synonyms}/{total_slots} ({slots_with_synonyms/total_slots*100:.1f}%)")
        
        return slots_with_synonyms == total_slots
        
    except Exception as e:
        print(f"âŒ æ•´åˆå®Œæ•´æ€§æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_extraction_methods():
    """æ¸¬è©¦æå–æ–¹æ³•é…ç½®"""
    print("\n=== æ¸¬è©¦æå–æ–¹æ³•é…ç½® ===\n")
    
    try:
        default_slots_path = Path(__file__).parent / "libs" / "mgfd_cursor" / "humandata" / "default_slots.json"
        
        with open(default_slots_path, 'r', encoding='utf-8') as f:
            default_slots = json.load(f)
        
        collection_strategy = default_slots["collection_strategy"]
        extraction_methods = collection_strategy.get("extraction_methods", {})
        
        print("ğŸ”§ æå–æ–¹æ³•é…ç½®:")
        print(f"   ä¸»è¦æ–¹æ³•: {extraction_methods.get('primary', 'N/A')}")
        print(f"   å¾Œå‚™æ–¹æ³•: {extraction_methods.get('fallback', 'N/A')}")
        
        strategies = extraction_methods.get("strategies", {})
        print(f"\nğŸ“‹ ç­–ç•¥é…ç½®:")
        
        total_weight = 0
        for strategy_name, config in strategies.items():
            enabled = config.get("enabled", False)
            weight = config.get("weight", 0)
            total_weight += weight
            
            status = "âœ…" if enabled else "âŒ"
            print(f"   {status} {strategy_name}: æ¬Šé‡={weight}, å•Ÿç”¨={enabled}")
        
        print(f"\nğŸ“Š æ¬Šé‡ç¸½å’Œ: {total_weight:.2f}")
        
        # é©—è­‰æ¬Šé‡ç¸½å’Œæ¥è¿‘1.0
        if 0.95 <= total_weight <= 1.05:
            print("   âœ… æ¬Šé‡é…ç½®åˆç†")
            return True
        else:
            print("   âš ï¸  æ¬Šé‡é…ç½®éœ€è¦èª¿æ•´")
            return False
        
    except Exception as e:
        print(f"âŒ æå–æ–¹æ³•æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_synonym_quality():
    """æ¸¬è©¦åŒç¾©è©å“è³ª"""
    print("\n=== æ¸¬è©¦åŒç¾©è©å“è³ª ===\n")
    
    try:
        default_slots_path = Path(__file__).parent / "libs" / "mgfd_cursor" / "humandata" / "default_slots.json"
        
        with open(default_slots_path, 'r', encoding='utf-8') as f:
            default_slots = json.load(f)
        
        slot_definitions = default_slots["slot_definitions"]
        
        total_keywords = 0
        total_regex_patterns = 0
        total_semantic_terms = 0
        quality_issues = []
        
        for slot_name, slot_def in slot_definitions.items():
            if "synonyms" not in slot_def:
                continue
                
            synonyms = slot_def["synonyms"]
            
            for value_name, value_synonyms in synonyms.items():
                # çµ±è¨ˆé—œéµè©
                keywords = value_synonyms.get("keywords", [])
                total_keywords += len(keywords)
                
                # çµ±è¨ˆæ­£å‰‡è¡¨é”å¼
                regex_patterns = value_synonyms.get("regex", [])
                total_regex_patterns += len(regex_patterns)
                
                # çµ±è¨ˆèªç¾©è¡“èª
                semantic_terms = value_synonyms.get("semantic", [])
                total_semantic_terms += len(semantic_terms)
                
                # å“è³ªæª¢æŸ¥
                if len(keywords) == 0:
                    quality_issues.append(f"{slot_name}.{value_name}: ç¼ºå°‘é—œéµè©")
                
                if len(regex_patterns) == 0:
                    quality_issues.append(f"{slot_name}.{value_name}: ç¼ºå°‘æ­£å‰‡è¡¨é”å¼")
                
                if len(semantic_terms) == 0:
                    quality_issues.append(f"{slot_name}.{value_name}: ç¼ºå°‘èªç¾©è¡“èª")
        
        print("ğŸ“Š åŒç¾©è©çµ±è¨ˆ:")
        print(f"   ç¸½é—œéµè©æ•¸: {total_keywords}")
        print(f"   ç¸½æ­£å‰‡è¡¨é”å¼æ•¸: {total_regex_patterns}")
        print(f"   ç¸½èªç¾©è¡“èªæ•¸: {total_semantic_terms}")
        
        if quality_issues:
            print(f"\nâš ï¸  å“è³ªå•é¡Œ:")
            for issue in quality_issues:
                print(f"   - {issue}")
            return False
        else:
            print(f"\nâœ… åŒç¾©è©å“è³ªè‰¯å¥½")
            return True
        
    except Exception as e:
        print(f"âŒ åŒç¾©è©å“è³ªæ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_backward_compatibility():
    """æ¸¬è©¦å‘å¾Œç›¸å®¹æ€§"""
    print("\n=== æ¸¬è©¦å‘å¾Œç›¸å®¹æ€§ ===\n")
    
    try:
        # è¼‰å…¥åŸå§‹æª”æ¡ˆé€²è¡Œæ¯”è¼ƒ
        default_slots_path = Path(__file__).parent / "libs" / "mgfd_cursor" / "humandata" / "default_slots.json"
        slot_synonyms_path = Path(__file__).parent / "libs" / "mgfd_cursor" / "humandata" / "slot_synonyms.json"
        
        with open(default_slots_path, 'r', encoding='utf-8') as f:
            default_slots = json.load(f)
        
        with open(slot_synonyms_path, 'r', encoding='utf-8') as f:
            slot_synonyms = json.load(f)
        
        # æª¢æŸ¥æ§½ä½åç¨±ç›¸å®¹æ€§
        default_slot_names = set(default_slots["slot_definitions"].keys())
        synonym_slot_names = set(slot_synonyms.keys())
        
        print("ğŸ” æ§½ä½åç¨±ç›¸å®¹æ€§:")
        
        # æª¢æŸ¥default_slotsä¸­çš„æ§½ä½æ˜¯å¦åœ¨slot_synonymsä¸­å­˜åœ¨
        missing_in_synonyms = default_slot_names - synonym_slot_names
        if missing_in_synonyms:
            print(f"   âš ï¸  åœ¨slot_synonymsä¸­ç¼ºå°‘çš„æ§½ä½: {missing_in_synonyms}")
        else:
            print(f"   âœ… æ‰€æœ‰æ§½ä½åç¨±ç›¸å®¹")
        
        # æª¢æŸ¥æ§½ä½å€¼ç›¸å®¹æ€§
        print(f"\nğŸ” æ§½ä½å€¼ç›¸å®¹æ€§:")
        compatible_slots = 0
        total_slots = len(default_slot_names & synonym_slot_names)
        
        for slot_name in default_slot_names & synonym_slot_names:
            default_values = set(default_slots["slot_definitions"][slot_name]["validation_rules"]["allowed_values"])
            synonym_values = set(slot_synonyms[slot_name].keys())
            
            if default_values == synonym_values:
                print(f"   âœ… {slot_name}: å€¼å®Œå…¨ç›¸å®¹")
                compatible_slots += 1
            else:
                missing_values = default_values - synonym_values
                extra_values = synonym_values - default_values
                print(f"   âš ï¸  {slot_name}: å€¼ä¸å®Œå…¨ç›¸å®¹")
                if missing_values:
                    print(f"      ç¼ºå°‘: {missing_values}")
                if extra_values:
                    print(f"      é¡å¤–: {extra_values}")
        
        compatibility_rate = compatible_slots / total_slots if total_slots > 0 else 0
        print(f"\nğŸ“Š ç›¸å®¹æ€§æ¯”ç‡: {compatible_slots}/{total_slots} ({compatibility_rate*100:.1f}%)")
        
        return compatibility_rate >= 0.8  # 80%ç›¸å®¹æ€§ç‚ºé€šé
        
    except Exception as e:
        print(f"âŒ å‘å¾Œç›¸å®¹æ€§æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_enhanced_features():
    """æ¸¬è©¦å¢å¼·åŠŸèƒ½"""
    print("\n=== æ¸¬è©¦å¢å¼·åŠŸèƒ½ ===\n")
    
    try:
        default_slots_path = Path(__file__).parent / "libs" / "mgfd_cursor" / "humandata" / "default_slots.json"
        
        with open(default_slots_path, 'r', encoding='utf-8') as f:
            default_slots = json.load(f)
        
        # æ¸¬è©¦æ­£å‰‡è¡¨é”å¼åŠŸèƒ½
        print("ğŸ” æ¸¬è©¦æ­£å‰‡è¡¨é”å¼åŠŸèƒ½...")
        regex_count = 0
        for slot_name, slot_def in default_slots["slot_definitions"].items():
            if "synonyms" in slot_def:
                for value_name, value_synonyms in slot_def["synonyms"].items():
                    regex_patterns = value_synonyms.get("regex", [])
                    regex_count += len(regex_patterns)
        
        print(f"   âœ… æ­£å‰‡è¡¨é”å¼æ¨¡å¼æ•¸: {regex_count}")
        
        # æ¸¬è©¦èªç¾©åŒ¹é…åŠŸèƒ½
        print("\nğŸ” æ¸¬è©¦èªç¾©åŒ¹é…åŠŸèƒ½...")
        semantic_count = 0
        for slot_name, slot_def in default_slots["slot_definitions"].items():
            if "synonyms" in slot_def:
                for value_name, value_synonyms in slot_def["synonyms"].items():
                    semantic_terms = value_synonyms.get("semantic", [])
                    semantic_count += len(semantic_terms)
        
        print(f"   âœ… èªç¾©è¡“èªæ•¸: {semantic_count}")
        
        # æ¸¬è©¦ä¾è³´é—œä¿‚
        print("\nğŸ”— æ¸¬è©¦ä¾è³´é—œä¿‚...")
        dependencies = default_slots["dependencies"]
        dependency_count = len(dependencies)
        print(f"   âœ… ä¾è³´é—œä¿‚æ•¸: {dependency_count}")
        
        # æ¸¬è©¦é©—è­‰è¦å‰‡
        print("\nâœ… æ¸¬è©¦é©—è­‰è¦å‰‡...")
        validation_rules = default_slots["validation_rules"]
        global_rules = validation_rules.get("global", {})
        slot_specific_rules = validation_rules.get("slot_specific", {})
        
        print(f"   âœ… å…¨å±€è¦å‰‡: {len(global_rules)} å€‹")
        print(f"   âœ… æ§½ä½ç‰¹å®šè¦å‰‡: {len(slot_specific_rules)} å€‹")
        
        # æ¸¬è©¦å¾Œå‚™ç­–ç•¥
        print("\nğŸ”„ æ¸¬è©¦å¾Œå‚™ç­–ç•¥...")
        fallback_strategy = default_slots["fallback_strategy"]
        fallback_types = ["incomplete_slots", "ambiguous_input", "no_match"]
        
        for fallback_type in fallback_types:
            if fallback_type in fallback_strategy:
                print(f"   âœ… {fallback_type}: å·²é…ç½®")
            else:
                print(f"   âŒ {fallback_type}: æœªé…ç½®")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¢å¼·åŠŸèƒ½æ¸¬è©¦å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹æ¸¬è©¦æ•´åˆå¾Œçš„default_slots.json...")
    
    # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    integration_success = test_integration_completeness()
    extraction_success = test_extraction_methods()
    quality_success = test_synonym_quality()
    compatibility_success = test_backward_compatibility()
    enhanced_success = test_enhanced_features()
    
    if all([integration_success, extraction_success, quality_success, compatibility_success, enhanced_success]):
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        print("ğŸ“‹ æ•´åˆæ‘˜è¦:")
        print("   - æ§½ä½åŒç¾©è©å®Œæ•´æ•´åˆ")
        print("   - æå–æ–¹æ³•é…ç½®æ­£ç¢º")
        print("   - åŒç¾©è©å“è³ªè‰¯å¥½")
        print("   - å‘å¾Œç›¸å®¹æ€§ä¿æŒ")
        print("   - å¢å¼·åŠŸèƒ½å®Œæ•´")
        print("\nâœ¨ æ•´åˆæˆåŠŸï¼default_slots.jsonç¾åœ¨åŒ…å«:")
        print("   - å®Œæ•´çš„æ§½ä½å®šç¾©å’Œé©—è­‰è¦å‰‡")
        print("   - å¤šå±¤æ¬¡åŒç¾©è©åŒ¹é…ï¼ˆé—œéµè©ã€æ­£å‰‡ã€èªç¾©ï¼‰")
        print("   - æ™ºèƒ½ä¾è³´é—œä¿‚ç®¡ç†")
        print("   - éˆæ´»çš„å¾Œå‚™ç­–ç•¥")
        print("   - æ··åˆæå–æ–¹æ³•é…ç½®")
    else:
        print("\nğŸ’¥ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—")
        if not integration_success:
            print("   - æ•´åˆå®Œæ•´æ€§æ¸¬è©¦å¤±æ•—")
        if not extraction_success:
            print("   - æå–æ–¹æ³•é…ç½®æ¸¬è©¦å¤±æ•—")
        if not quality_success:
            print("   - åŒç¾©è©å“è³ªæ¸¬è©¦å¤±æ•—")
        if not compatibility_success:
            print("   - å‘å¾Œç›¸å®¹æ€§æ¸¬è©¦å¤±æ•—")
        if not enhanced_success:
            print("   - å¢å¼·åŠŸèƒ½æ¸¬è©¦å¤±æ•—")
