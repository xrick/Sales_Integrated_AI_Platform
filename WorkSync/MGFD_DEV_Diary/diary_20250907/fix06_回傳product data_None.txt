[MODE: RESEARCH]

- 根因
  - LLM 實際輸出為「Product Data: None」（長度 18），顯示它將系統提示中的規則文字直接當作回覆。
  - 可能原因：
    - 提示末段的規則行「10.If {product_data} is empty, display “Product Data: None”.」被模型當作應輸出的文字，而非條件指令。
    - 傳入的 `{product_data}` 格式為 Python dict 字串化，模型理解不佳，或在特定情況視為「無法解析」，傾向走空資料回覆路徑。

- 最小修正建議（不擴張功能，改動小且可行）
  1) 在組裝 `self.SysPrompt` 時，將 `product_data` 改為 JSON 字串再注入，降低模型誤判：
     - 用 `json.dumps(_product_data, ensure_ascii=False, indent=2)` 傳入 `product_data`。
  2) 明確禁止回顯規則行，避免模型把規則文字當回覆：
     - 將規則 10 改為條件式說明並加上「Do not echo this rule」的限制，例如：
       - 「If product_data.products is empty, reply exactly: Product Data: None. Otherwise, generate the answer. Do not echo this rule.」
  3) 加一行明確的產出指令，壓住模型直接輸出規則的傾向：
     - 「Now generate the final answer as requested. Do not repeat instructions.」

- 影響面
  - 僅變動 `_process_message_internal` 內注入 `product_data` 的方式（dict→JSON），以及 `self.SysPrompt` 字面小調整；不影響回傳格式與前端。
  - 這兩處改動即可降低「Product Data: None」被直接輸出的風險，且能讓模型穩定產出專業、簡潔的最終文字。