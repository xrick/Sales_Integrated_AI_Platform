# libs/MGFDKernel.py
"""
MGFD æ ¸å¿ƒæ§åˆ¶å™¨ - ç³»çµ±å¤§è…¦åŠå°å¤–å”¯ä¸€ä»‹é¢
è² è²¬å”èª¿äº”å¤§æ¨¡çµ„ï¼Œç®¡ç†å°è©±æµç¨‹ï¼Œè™•ç†å‰ç«¯è«‹æ±‚
å¾Œç«¯è™•ç†å®Œç•¢ï¼Œå›è¦†çµ¦å‰ç«¯çš„æ ¼å¼:
return {
        "success": True,
        "session_id": session_id,
        "message": "LLM Responses",
        "timestamp": datetime.now().isoformat()
        }
"""

import logging
import json
import redis
from typing import Dict, Any, Optional, List
import asyncio
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass

# å°å…¥å…¶ä»–æ¨¡çµ„ï¼ˆå¾…å¯¦ä½œï¼‰
# from .UserInputHandler import UserInputHandler
# from .StateManageHandler import StateManagementHandler
# from .PromptManagementHandler import PromptManagementHandler
# from .KnowledgeManageHandler import KnowledgeManagementHandler
# from .ResponseGenHandler import ResponseGenHandler
from .UserInputHandler.UserInputHandler import UserInputHandler
from .UserInputHandler import CheckUtils
from .StateManageHandler.StateManagementHandler import StateManagementHandler
from .PromptManagementHandler import prompt_manager
from .KnowledgeManageHandler.knowledge_manager import KnowledgeManager
from .ResponseGenHandler import ResponseGenHandler
from dataclasses import dataclass
from .RAG.LLM.LLMInitializer import LLMInitializer
from langchain.prompts import PromptTemplate
import re
import ast
logger = logging.getLogger(__name__)

###setup debug
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

@dataclass
class StateStatus:
    keyword_matched: str
    keyword_not_matched: str
    need_data_query:str
    no_data_query:str
    default:str

@dataclass
class States:
    OnInit: str
    OnReceiveMsg: str
    OnResponseMsg: str
    OnGenFunnelChat: str
    OnGenMDContent: str
    OnDataQuery: str
    OnQueriedDataProcessing: str
    OnSendFront: str
    OnWaitMsg: str


class MGFDKernel:
    """
    MGFD ç³»çµ±æ ¸å¿ƒæ§åˆ¶å™¨
    è·è²¬ï¼šå”èª¿äº”å¤§æ¨¡çµ„ï¼Œç®¡ç†å°è©±æµç¨‹ï¼Œè™•ç†å‰ç«¯è«‹æ±‚
    """
    def __init__(self, redis_client: Optional[redis.Redis] = None) -> None:
        """
        åˆå§‹åŒ– MGFD æ ¸å¿ƒæ§åˆ¶å™¨ 
        Args:
            redis_client: Redis å®¢æˆ¶ç«¯å¯¦ä¾‹ï¼Œç”¨æ–¼æœƒè©±ç‹€æ…‹æŒä¹…åŒ–
        """
        # å˜—è©¦åˆå§‹åŒ– LLMï¼ˆæœ€å°è®Šæ›´ï¼›å¤±æ•—å‰‡ä¿æŒå›é€€æ©Ÿåˆ¶ï¼‰
        self.llm = None
        self.query_rule = None
        logger.info("LLM åˆå§‹åŒ–ä¸­...")
        try:
            self.llm_initializer = LLMInitializer(model_name="gpt-oss:20b", temperature=0.1, request_timeout=60)
            self.llm = self.llm_initializer.get_llm()
            logger.info("LLM åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"LLM åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡ä½¿ç”¨å›é€€æ©Ÿåˆ¶: {e}")
            self.llm_initializer = None
            self.llm = None
        # è‹¥ Kernel å…§æœªå–å¾— LLMï¼Œä¸” KnowledgeManager å…§å·²æœ‰ llmï¼Œå¯ä½œè®€å–å¼å‚™æ´
        # try:
        #     if self.llm is None and getattr(self, 'knowledge_manager', None) is not None:
        #         km_llm = getattr(self.knowledge_manager, 'llm', None)
        #         if km_llm is not None:
        #             self.llm = km_llm
        #             logger.info("æ¡ç”¨ KnowledgeManager ä¸­çš„ LLM ä½œç‚ºå‚™æ´")
        except Exception:
            # å®‰å…¨ä¿åº•ï¼Œä¸é˜»æ–·åˆå§‹åŒ–
            pass

        logger.info("MGFDKernel åˆå§‹åŒ–å®Œæˆ")
        # åˆå§‹åŒ–çŸ¥è­˜ç®¡ç†å™¨ï¼ˆåŒ…å« LLM åŠŸèƒ½ï¼‰
        self.user_input_handler = UserInputHandler()
        logger.info("user_input_handler åˆå§‹åŒ–æˆåŠŸ")
        self.knowledge_manager = KnowledgeManager()
        logger.info("knowledge_manager åˆå§‹åŒ–æˆåŠŸ")
        # self.jsonized_user_input = None
        self.redis_client = redis_client
        self.config = self._load_config()
        # è¼‰å…¥å¯æ“´å……çš„ NB ç‰¹å¾µå°ç…§è¡¨ï¼ˆç”¨æ–¼é—œéµåŠŸèƒ½åµæ¸¬èˆ‡æ¯”å°ï¼‰
        self.nb_feature_table = self._load_nb_feature_table()
        self.ComparableNB_NUM=6
        #self.slot_schema = self._load_slot_schema()
        self.MAX_CONTEXT_TOKENS = 131072  # gpt-oss:20b context limit
        # Initialize states and state_status before state_machine to avoid AttributeError
        self.states = States(
            OnInit="OnInit",
            OnReceiveMsg="OnReceiveMsg",
            OnResponseMsg="OnResponseMsg",
            OnGenFunnelChat="OnGenFunnelChat",
            OnGenMDContent="OnGenMDContent",
            OnDataQuery="OnDataQuery",
            OnQueriedDataProcessing="OnQueriedDataProcessing",
            OnSendFront="OnSendFront",
            OnWaitMsg="OnWaitMsg"
        )
        self.state_status = StateStatus(
            keyword_matched="keyword_matched",
            keyword_not_matched="keyword_not_matched",
            need_data_query="need_data_query",
            no_data_query="no_data_query",
            default="default"
        )
        
        # Load state machine after state_status is initialized
        self.state_machine = self._load_state_machine()
        # Welcome Prompt
        self.welcome_prompt = self._load_welcome_prompt()
        # self.prompt_using = """
        #     èº«ç‚ºä¸€åå°ˆæ¥­ä¸”è¦ªåˆ‡çš„ç­†è¨˜å‹é›»è…¦éŠ·å”®å°ˆå®¶ï¼Œä½ çš„ä»»å‹™æ˜¯ä¸»å‹•è¿æ¥é€²å…¥è³£å ´çš„å®¢æˆ¶ï¼Œä¸¦å¼•å°ä»–å€‘å®Œæˆä¸€æ®µæ„‰å¿«ä¸”æœ‰æ•ˆç‡çš„è³¼ç‰©é«”é©—ã€‚
        #     ä½ çš„å°è©±æ‡‰éµå¾ªä»¥ä¸‹çµæ§‹èˆ‡åŸå‰‡ï¼š

        #     **1. ç†±æƒ…é–‹å ´èˆ‡åˆæ­¥æ¢ç´¢ï¼š**
        #     * ç”¨æº«æš–ä¸”é–‹æ”¾å¼çš„å•å€™é–‹å§‹å°è©±ï¼Œä¾‹å¦‚ï¼šã€Œæ‚¨å¥½ï¼Œæ­¡è¿å…‰è‡¨ï¼æƒ³æ‰¾ä¸€å°ä»€éº¼æ¨£çš„ç­†è¨˜å‹é›»è…¦å‘¢ï¼Ÿé‚„æ˜¯å…ˆéš¨æ„çœ‹çœ‹ï¼Ÿã€
        #     * é¿å…çµ¦äºˆå£“åŠ›ï¼Œè®“å®¢æˆ¶æ„Ÿåˆ°è¼•é¬†è‡ªåœ¨ã€‚

        #     **2. å¼•å°å¼éœ€æ±‚åˆ†æï¼ˆæ ¸å¿ƒä»»å‹™ï¼‰ï¼š**
        #     ä½ çš„ç›®æ¨™æ˜¯é€éç²¾æº–æå•ï¼Œåƒåµæ¢ä¸€æ¨£æ‹¼æ¹Šå‡ºå®¢æˆ¶çš„çœŸå¯¦éœ€æ±‚ã€‚è«‹ä¾åºè©¢å•ä»¥ä¸‹é—œéµå•é¡Œï¼Œä¸¦æ ¹æ“šå®¢æˆ¶çš„å›ç­”è¿½å•ç´°ç¯€ï¼š
        #     * **ä¸»è¦ç”¨é€”ï¼š** ã€Œè«‹å•æ‚¨è²·é€™å°é›»è…¦ï¼Œæœ€ä¸»è¦æ˜¯ç”¨ä¾†åšä»€éº¼å‘¢ï¼Ÿä¾‹å¦‚æ˜¯å·¥ä½œã€ä¸Šèª²ã€ç©éŠæˆ²ï¼Œé‚„æ˜¯å–®ç´”ä¸Šç¶²è¿½åŠ‡ï¼Ÿã€
        #     * **è»Ÿé«”èˆ‡å ´æ™¯ï¼š**
        #         * ï¼ˆå¦‚æœå·¥ä½œ/ä¸Šèª²ï¼‰ï¼šã€Œæœƒå¸¸ç”¨åˆ°å“ªäº›æ¯”è¼ƒç‰¹åˆ¥çš„è»Ÿé«”å—ï¼Ÿåƒæ˜¯å‰ªè¼¯å½±ç‰‡ã€å¯«ç¨‹å¼æˆ–è·‘æ•¸æ“šåˆ†æï¼Ÿã€
        #         * ï¼ˆå¦‚æœç©éŠæˆ²ï¼‰ï¼šã€Œå¹³å¸¸å–œæ­¡ç©å“ªä¸€ç¨®é¡å‹çš„éŠæˆ²å‘¢ï¼Ÿã€
        #     * **ä¾¿æ”œæ€§èˆ‡è¢å¹•ï¼š** ã€Œæœƒç¶“å¸¸éœ€è¦æŠŠå®ƒå¸¶å‡ºé–€å—ï¼Ÿå°æ–¼è¢å¹•å¤§å°æˆ–é‡é‡æœ‰æ²’æœ‰ç‰¹åˆ¥çš„åå¥½ï¼Ÿã€
        #     * **é ç®—ç¯„åœï¼š** ã€Œæ–¹ä¾¿è«‹å•ä¸€ä¸‹æ‚¨çš„é ç®—å¤§æ¦‚æ˜¯å¤šå°‘å‘¢ï¼Ÿæˆ‘èƒ½æ›´å¥½åœ°å¹«æ‚¨ç¯©é¸å‡ºCPå€¼æœ€é«˜çš„é¸æ“‡ã€‚ã€
        #     * **å“ç‰Œèˆ‡åå¥½ï¼š** ã€Œéå»æœ‰ç”¨éå“ªå€‹å“ç‰Œçš„é›»è…¦å—ï¼Ÿæœ‰æ²’æœ‰ç‰¹åˆ¥å–œæ­¡æˆ–ä¸å–œæ­¡çš„å“ç‰Œï¼Ÿã€
        #     * **é—œéµè€ƒé‡ï¼š** ã€Œå°æ‚¨ä¾†èªªï¼Œä¸€å°ç†æƒ³çš„ç­†é›»ï¼Œæœ€ä¸èƒ½å¦¥å”çš„åŠŸèƒ½æ˜¯ä»€éº¼ï¼Ÿæ˜¯æ•ˆèƒ½ã€é›»æ± çºŒèˆªåŠ›ï¼Œé‚„æ˜¯è¢å¹•çš„ç•«è³ªï¼Ÿã€

        #     **3. ç¢ºèªéœ€æ±‚èˆ‡æå‡ºæ–¹æ¡ˆï¼š**
        #     * åœ¨æå•å¾Œï¼Œç”¨ä¸€å¥è©±ç¸½çµä¸¦ç¢ºèªå®¢æˆ¶çš„éœ€æ±‚ã€‚ä¾‹å¦‚ï¼šã€Œå¥½çš„ï¼Œæ‰€ä»¥æˆ‘å¹«æ‚¨æ•´ç†ä¸€ä¸‹ï¼Œæ‚¨éœ€è¦ä¸€å°æ–¹ä¾¿æ”œå¸¶ã€çºŒèˆªåŠ›é•·ï¼Œä¸»è¦ç”¨ä¾†æ–‡æ›¸è™•ç†å’Œçœ‹å½±ç‰‡ï¼Œé ç®—åœ¨ä¸‰è¬å·¦å³çš„ç­†é›»ï¼Œå°å—ï¼Ÿã€
        #     * æ ¹æ“šç¢ºèªå¾Œçš„éœ€æ±‚ï¼Œæå‡º 2-3 æ¬¾æœ€ç¬¦åˆçš„ç­†é›»é¸é …ã€‚
        #     * ä»‹ç´¹æ¯æ¬¾ç­†é›»æ™‚ï¼Œä¸è¦åªè¬›è¦æ ¼ï¼Œè¦å¼·èª¿ã€Œå®ƒèƒ½ç‚ºå®¢æˆ¶å¸¶ä¾†çš„å¥½è™•ã€ã€‚ä¾‹å¦‚ï¼Œèˆ‡å…¶èªªã€Œå®ƒæœ‰16GB RAMã€ï¼Œä¸å¦‚èªªã€Œå®ƒæœ‰16GBçš„è¨˜æ†¶é«”ï¼Œæ‰€ä»¥æ‚¨åŒæ™‚é–‹å¾ˆå¤šç¶²é å’Œæ–‡ä»¶éƒ½ä¸æœƒå¡é “ï¼Œéå¸¸é †æš¢ã€‚ã€

        #     **4. è™•ç†ç–‘æ…®èˆ‡å®ŒæˆéŠ·å”®ï¼š**
        #     * è€å¿ƒå›ç­”å®¢æˆ¶å°æ¨è–¦ç”¢å“çš„ä»»ä½•å•é¡Œã€‚
        #     * å¦‚æœå®¢æˆ¶çŒ¶è±«ä¸æ±ºï¼Œå¯ä»¥ä¸»å‹•è©¢å•ï¼šã€Œé€™å¹¾æ¬¾æ‚¨æ¯”è¼ƒå–œæ­¡å“ªä¸€å°çš„è¨­è¨ˆå‘¢ï¼Ÿæˆ–æ˜¯æ‚¨é‚„åœ¨æ„å“ªå€‹éƒ¨åˆ†ï¼Œæˆ‘å†å¹«æ‚¨èªªæ˜ï¼Ÿã€
        #     * æœ€å¾Œï¼Œä»¥è¦ªåˆ‡çš„æ…‹åº¦å”åŠ©å®¢æˆ¶å®Œæˆè³¼è²·æµç¨‹æˆ–æä¾›å¾ŒçºŒè³‡è¨Šã€‚

        #     **äº’å‹•æº–å‰‡ï¼š**
        #     * **èªæ°£ï¼š** å§‹çµ‚ä¿æŒå°ˆæ¥­ã€å‹å–„ã€è€å¿ƒä¸”å……æ»¿ç†±å¿±ã€‚
        #     * **ç›®æ¨™ï¼š** ä½ çš„è§’è‰²æ˜¯ã€Œé¡§å•ã€ï¼Œä¸æ˜¯ã€Œæ¨éŠ·å“¡ã€ã€‚å°ˆæ³¨æ–¼è§£æ±ºå®¢æˆ¶çš„å•é¡Œï¼Œè€Œéåƒ…åƒ…è³£å‡ºæœ€è²´çš„å•†å“ã€‚
        #     * **é¿å…ï¼š** ä¸è¦ä½¿ç”¨éæ–¼æ·±å¥§çš„æŠ€è¡“è¡“èªï¼Œç›¡é‡ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»ä¾†è§£é‡‹ã€‚

        #     **åš´æ ¼éµå®ˆä½¿ç”¨å…§éƒ¨è³‡æ–™:**: è«‹çµ•å°å‹™å¿…åš´æ ¼éµå®ˆå…¬å¸ç”¢å“è³‡æ–™éƒ½å®Œå…¨ä¾†è‡ªå…¬å¸å…§éƒ¨æä¾›çš„å„ç¨®è³‡æ–™ï¼Œåš´æ ¼ç¦æ­¢å‡ºç¾ç«¶çˆ­å…¬å¸è³‡æ–™ã€‚

       
        # System-level prompt template (å„ªåŒ–ç‰ˆ - æ¸›å°‘ 70% Token æ¶ˆè€—)
        # æ³¨æ„ï¼šé€™æ˜¯ä¸å¯è®Šçš„æ¨¡æ¿ï¼Œé¿å…ç‹€æ…‹æ±¡æŸ“

        self.query_prompt = """
            ä½ æ˜¯ä¸€ä½ç²¾æº–çš„ç”¢å“æ„åœ–åˆ†æå¸«ã€‚ä½ çš„ä»»å‹™æ˜¯å¾ä½¿ç”¨è€…æä¾›çš„ç­†é›»ç”¢å“æŸ¥è©¢ä¸­ï¼Œç²¾æº–åœ°è§£æä¸¦çµæ§‹åŒ–å‡ºä»¥ä¸‹ä¸‰å€‹æ ¸å¿ƒè³‡è¨Šï¼šä½¿ç”¨è€…æ„åœ–ã€æåŠçš„ç”¢å“å¯¦é«”ã€ä»¥åŠç›¸é—œçš„å±¬æ€§ç‰¹å¾µã€‚

            ---

            ### **[ä»»å‹™èªªæ˜]**
            1. **æ„åœ–è­˜åˆ¥ (intent)**ï¼šåˆ¤æ–·ä½¿ç”¨è€…æŸ¥è©¢çš„æ„åœ–ã€‚å¸¸è¦‹æ„åœ–åŒ…æ‹¬ä½†ä¸é™æ–¼ï¼š
                - `recommend` (æ¨è–¦)ï¼šä½¿ç”¨è€…æƒ³ç²å¾—ç”¢å“æ¨è–¦ï¼Œé€šå¸¸ä¸æŒ‡å®šå…·é«”å‹è™Ÿã€‚
                - `spec_check` (è¦æ ¼æŸ¥è©¢)ï¼šä½¿ç”¨è€…æƒ³æŸ¥è©¢ç‰¹å®šç”¢å“çš„è¦æ ¼ç´°ç¯€ã€‚
                - `compare` (æ¯”è¼ƒ)ï¼šä½¿ç”¨è€…æƒ³æ¯”è¼ƒå¤šå€‹ç”¢å“æˆ–ç³»åˆ—ä¹‹é–“çš„å·®ç•°ã€‚
                - `feature_explanation` (åŠŸèƒ½è§£é‡‹)ï¼šä½¿ç”¨è€…æƒ³äº†è§£æŸå€‹åŠŸèƒ½æˆ–æŠ€è¡“çš„é‹ä½œæ–¹å¼ã€‚
                - `product_introduction` (ç”¢å“ä»‹ç´¹)ï¼šä½¿ç”¨è€…æƒ³å°æŸå€‹ç”¢å“æœ‰å…¨é¢çš„äº†è§£ã€‚
            2. **å¯¦é«”è§£æ (entities)**ï¼šå¾æŸ¥è©¢ä¸­è­˜åˆ¥å‡ºæ‰€æœ‰æ˜ç¢ºæåŠçš„ç­†é›»å‹è™Ÿã€ç³»åˆ—åç¨±æˆ–ç”¢å“ä»£ç¢¼ã€‚
            3. **å±¬æ€§è§£æ (attributes)**ï¼šå¾æŸ¥è©¢ä¸­æå–å‡ºèˆ‡æ„åœ–ç›¸é—œçš„æŠ€è¡“å±¬æ€§æˆ–ç‰¹å¾µã€‚è«‹åƒè€ƒä¸‹æ–¹æä¾›çš„ç‰¹å¾µåˆ—è¡¨ã€‚

            ---

            ### **[ç‰¹å¾µåˆ—è¡¨ (Attributes)]**
            è«‹ä»”ç´°åƒè€ƒä»¥ä¸‹ç­†é›»ç›¸é—œçš„å±¬æ€§æ¨™ç±¤ï¼Œä¸¦åœ¨ **attributes** æ¬„ä½ä¸­å¡«å…¥æœ€ç›¸é—œçš„æ¨™ç±¤ã€‚
            - `modeltype` (æ©Ÿç¨®é¡å‹ï¼Œå¦‚ï¼šå•†ç”¨ã€é›»ç«¶)
            - `modelname` (ç”¢å“åç¨±æˆ–ä»£è™Ÿ)
            - `structconfig` (çµæ§‹é…ç½®ï¼Œå¦‚ï¼šé‡é‡ã€å°ºå¯¸ã€æè³ª)
            - `lcd` (è¢å¹•è¦æ ¼ï¼Œå¦‚ï¼šè§£æåº¦ã€æ›´æ–°ç‡)
            - `touchpanel` (è§¸æ§é¢æ¿)
            - `iointerface` (I/O æ¥å£ï¼Œå¦‚ï¼šUSB-Cã€HDMI)
            - `webcamera` (ç¶²è·¯æ”å½±æ©Ÿ)
            - `audio` (éŸ³è¨Šç³»çµ±)
            - `battery` (é›»æ± èˆ‡å……é›»)
            - `cpu` (è™•ç†å™¨)
            - `gpu` (ç¨ç«‹é¡¯ç¤ºå¡)
            - `memory` (è¨˜æ†¶é«”)
            - `lcdconnector` (è¢å¹•é€£æ¥å™¨)
            - `storage` (å„²å­˜è£ç½®)
            - `wifislot` (ç„¡ç·šç¶²å¡æ’æ§½)
            - `thermal` (æ•£ç†±ç³»çµ±)
            - `softwareconfig` (è»Ÿé«”é…ç½®)
            - `ai` (AI åŠŸèƒ½)
            - `accessory` (é€±é‚Šé…ä»¶)

            ---

            ### **[è¼¸å‡ºæ ¼å¼èˆ‡ç¯„ä¾‹ (Output Format & Examples)]**
            è«‹åƒ…ä»¥ JSON æ ¼å¼å›æ‡‰ï¼Œä¸åŒ…å«ä»»ä½•é¡å¤–æ–‡å­—æˆ–è§£é‡‹ã€‚(è«‹æ³¨æ„ï¼Œä¸è¦ç›´æ¥è¼¸å‡ºåˆ°å‰ç«¯Browser)
            ```json
            {
                "intent": "<è§£æå¾Œçš„ä½¿ç”¨è€…æ„åœ–>",
                "entities": ["<è­˜åˆ¥å‡ºçš„ç­†é›»å¯¦é«”ï¼Œå¯ç‚ºå¤šå€‹>"],
                "attributes": ["<ç›¸é—œçš„å±¬æ€§æ¨™ç±¤ï¼Œå¯ç‚ºå¤šå€‹>"],
                "language": "<ä½¿ç”¨è€…æŸ¥è©¢çš„èªè¨€>"
            }
        """
#####################################################################################
#         self.SysPromptTemplate = """ä½ æ˜¯å°ˆæ¥­çš„ç­†é›»éŠ·å”®é¡§å•ã€‚æ ¹æ“šä»¥ä¸‹ç”¢å“è³‡æ–™å›ç­”å®¢æˆ¶å•é¡Œï¼š

#         **æŸ¥è©¢è¨­å®š**
#         {query_rules}

#         **ç”¢å“è³‡æ–™ï¼š**
#         {product_data}

#         **å®¢æˆ¶éœ€æ±‚ï¼š**
#         {user_query}


# **è¼¸å‡ºæ ¼å¼ï¼š**
# 1.ç°¡æ½”çš„ Markdown æ ¼å¼ï¼ŒåŒ…å«ç”¢å“æ¨è–¦å’Œè¦æ ¼è¡¨æ ¼ã€‚
# 2.åš´æ ¼ç¦æ­¢è¼¸å‡ºå–®ç´”çš„JSONæ ¼å¼ã€‚
# """
        self.SysPromptTemplate = """ä½ æ˜¯å°ˆæ¥­çš„ç­†é›»éŠ·å”®é¡§å•ã€‚æ ¹æ“šä»¥ä¸‹ç”¢å“è³‡æ–™å›ç­”å®¢æˆ¶å•é¡Œï¼š

        # **æŸ¥è©¢è¨­å®š**
        {query_rules}

        #**ç”¢å“è³‡æ–™ï¼š**
        {product_data}

        #**å®¢æˆ¶éœ€æ±‚ï¼š**
        {user_query}

        


# **è¼¸å‡ºæ ¼å¼ï¼š**
# 1.ç°¡æ½”çš„ Markdown æ ¼å¼ï¼ŒåŒ…å«ç”¢å“æ¨è–¦å’Œè¦æ ¼è¡¨æ ¼ã€‚
# 2.åš´æ ¼ç¦æ­¢è¼¸å‡ºå–®ç´”çš„JSONæ ¼å¼ã€‚
# """
        # å®£å‘Šä¸‰å±¤å¼promptæ‰€éœ€è¦çš„è®Šæ•¸
        # self.product_data = None
        # self.prompt_using = None
        # self.answer = None
        # self.query = None
        # å®£å‘Šä¸‰å±¤å¼Prompt

        # åˆå§‹åŒ–äº”å¤§æ¨¡çµ„
        try:
            
            self.prompt_manager = prompt_manager.get_global_prompt_manager()
            # knowledge_manager å·²ç¶“åœ¨ __init__ é–‹é ­åˆå§‹åŒ–äº†
            self.response_generator = ResponseGenHandler()
            self.state_manager = StateManagementHandler(redis_client)
            logger.info("æ‰€æœ‰æ¨¡çµ„åˆå§‹åŒ–æˆåŠŸ")
            self.slot_schema = self.user_input_handler.slot_schema
        except Exception as e:
            logger.error(f"æ¨¡çµ„åˆå§‹åŒ–å¤±æ•—: {e}")
            # å¦‚æœåˆå§‹åŒ–å¤±æ•—ï¼Œè¨­ç½®ç‚º None
            self.user_input_handler = None
            self.prompt_manager = None
            self.knowledge_manager = None
            self.response_generator = None
            self.state_manager = None
        
        

    def _load_nb_feature_table(self) -> Dict[str, Any]:
        """
        è¼‰å…¥ config/nb_features_table.jsonï¼Œè‹¥ä¸å­˜åœ¨å‰‡å›å‚³é è¨­ç©ºè¡¨ã€‚
        """
        try:
            config_path = Path(__file__).resolve().parents[1] / "config" / "nb_features_table.json"
            if config_path.exists():
                with open(config_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    # æ­£è¦åŒ–ï¼šç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨
                    feats = data.get("features", [])
                    for fe in feats:
                        fe.setdefault("keywords", [])
                        fe.setdefault("regex", [])
                        fe.setdefault("search_fields", [])
                        fe.setdefault("weight", 10)
                    return {"version": data.get("version", "1.0"), "features": feats}
            else:
                logger.warning("æœªæ‰¾åˆ° nb_features_table.jsonï¼Œå°‡ä½¿ç”¨ç©ºè¡¨è¨­å®š")
                return {"version": "0", "features": []}
        except Exception as e:
            logger.error(f"è¼‰å…¥ nb_features_table.json å¤±æ•—: {e}")
            return {"version": "0", "features": []}
    
    def extract_markdown_tables(self, text: str) -> List[str]:
        """
        å¾æ–‡å­—ä¸­æå–æ‰€æœ‰ Markdown è¡¨æ ¼ï¼Œä¸¦ä»¥ list å½¢å¼å›å‚³ã€‚

        Args:
            text (str): è¼¸å…¥çš„å®Œæ•´æ–‡å­—

        Returns:
            List[str]: æ‰€æœ‰æ‰¾åˆ°çš„ Markdown è¡¨æ ¼ï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹å­—ä¸²
        """
        # ä½¿ç”¨ regex æ‰¾å‡º markdown è¡¨æ ¼
        table_pattern = re.compile(
            r"\|.*?\|\n\|[-:\s|]+\|\n(?:\|.*?\|\n?)+",
            re.DOTALL
        )
        tables = table_pattern.findall(text)
        return tables
    
    def _postprocess_product_data(self, product_data: Dict[str, Any], max_products: int = 5) -> Dict[str, Any]:
        """
        æ‘˜è¦ç”¢å“æ•¸æ“šï¼Œåªä¿ç•™é—œéµè³‡è¨Šä»¥æ¸›å°‘ Token æ¶ˆè€—
        
        Args:
            product_data: åŸå§‹ç”¢å“æ•¸æ“š
            max_products: æœ€å¤§ç”¢å“æ•¸é‡
            
        Returns:
            æ‘˜è¦å¾Œçš„ç”¢å“æ•¸æ“š
        """
        if not isinstance(product_data, dict) or not product_data.get("products"):
            return product_data
            
        products = product_data.get("products", [])

        # ä¾æ“šæŸ¥è©¢èˆ‡ matched_keys é€²è¡Œå„ªå…ˆæ’åºï¼Œç¢ºä¿æœ€ç›¸é—œç”¢å“ä¸æœƒè¢«æˆªæ–·
        try:
            query_text = (product_data.get("query") or "").strip()
            q_lower = query_text.lower()
            matched_keys = set([str(k).strip() for k in (product_data.get("matched_keys") or []) if str(k).strip()])

            # é€šç”¨ç‰¹å¾µæ¯”å°ï¼šæ ¹æ“š JSON ç‰¹å¾µè¡¨å°æŸ¥è©¢èˆ‡ç”¢å“å…§å®¹é€²è¡ŒåŒ¹é…ä¸¦çµ¦åˆ†
            def feature_score_and_hits(prod: Dict[str, Any]) -> (int, List[str]):
                total = 0
                hits: List[str] = []
                features = (self.nb_feature_table or {}).get("features", [])
                # é å…ˆå°‡ç”¢å“å„æ¬„ä½è½‰å°å¯«
                field_texts = {}
                for fld in ["cpu", "gpu", "memory", "storage", "lcd", "battery", "audio", "wireless", "bluetooth"]:
                    field_texts[fld] = str(prod.get(fld, "") or "").lower()
                for fe in features:
                    fe_id = fe.get("id", "")
                    weight = int(fe.get("weight", 10))
                    keys = [str(k).lower() for k in fe.get("keywords", [])]
                    regs = fe.get("regex", [])
                    search_fields = fe.get("search_fields", []) or list(field_texts.keys())

                    # æŸ¥è©¢å‘½ä¸­
                    q_hit = any(k in q_lower for k in keys) if keys else False

                    # ç”¢å“æ¬„ä½å‘½ä¸­ï¼ˆé—œéµå­—æˆ– regexï¼‰
                    p_hit = False
                    for fld in search_fields:
                        txt = field_texts.get(fld, "")
                        if not txt:
                            continue
                        if keys and any(k in txt for k in keys):
                            p_hit = True
                            break
                        # regex æª¢æŸ¥
                        for rpat in regs:
                            try:
                                if re.search(rpat, txt):
                                    p_hit = True
                                    break
                            except Exception:
                                continue
                        if p_hit:
                            break

                    # è¨ˆåˆ†é‚è¼¯ï¼šé›™å‘½ä¸­ > ç”¢å“å‘½ä¸­ > åªæŸ¥è©¢å‘½ä¸­
                    if q_hit and p_hit:
                        total += weight * 2
                        hits.append(fe_id)
                    elif p_hit:
                        total += weight
                        hits.append(fe_id)
                    elif q_hit:
                        total += max(1, weight // 2)
                return total, hits

            def relevance_score(prod: Dict[str, Any], idx: int) -> int:
                score = 0
                modeltype = str(prod.get("modeltype", "")).strip()
                modelname = str(prod.get("modelname", "")).strip()

                # 1) Milvus å°æ‡‰éµå‘½ä¸­ï¼ˆæœ€å¼·è¨Šè™Ÿï¼‰
                if modeltype and modeltype in matched_keys:
                    score += 100

                # 2) ä½¿ç”¨è€…æŸ¥è©¢ä¸­ç›´æ¥å‡ºç¾å‹è™Ÿæˆ–ä»£ç¢¼
                if modelname and modelname.lower() in q_lower:
                    score += 60
                # å–®ç´”æ•¸å­—ä»£ç¢¼ï¼ˆå¦‚ 728ï¼‰åœ¨æŸ¥è©¢ä¸­å‡ºç¾
                if modeltype and modeltype.lower() in q_lower:
                    score += 120

                # 3) é€šç”¨ç‰¹å¾µåˆ†æ•¸ï¼ˆå¤šç‰¹å¾µå¯ç´¯åŠ ï¼‰
                f_score, _ = feature_score_and_hits(prod)
                score += f_score

                # 4) ä¿ç•™åŸå§‹é †åºçš„ç©©å®šæ€§ï¼ˆè¼ƒå°æ¬Šé‡ï¼Œé¿å…å®Œå…¨æ‰“äº‚ï¼‰
                score += max(0, 5 - min(idx, 5))
                return score

            # å…ˆæ‰“åˆ†å†æ’åº
            scored = [(relevance_score(p, i), i, p) for i, p in enumerate(products)]
            scored.sort(key=lambda x: (-x[0], x[1]))
            products = [p for _, __, p in scored[:max_products]]
        except Exception:
            # ç™¼ç”Ÿä»»ä½•ç•°å¸¸æ™‚ï¼Œé€€å›åˆ°åŸæœ¬çš„å‰ N ç­–ç•¥
            products = products[:max_products]
        
        summarized_products = []
        for product in products:
            # è¨ˆç®—ç‰¹å¾µå‘½ä¸­ï¼ˆä¾›è¡¨æ ¼èˆ‡æ¯”è¼ƒç”¨ï¼‰
            try:
                _, feature_hits = feature_score_and_hits(product)
            except Exception:
                feature_hits = []
            # åªä¿ç•™é—œéµè¦æ ¼ï¼Œå¤§å¹…æ¸›å°‘æ•¸æ“šé‡
            summarized_product = {
                "modeltype": product.get("modeltype", ""),
                "modelname": product.get("modelname", ""),
                "cpu_summary": self._extract_cpu_summary(product.get("cpu", "") or ""),
                "memory_summary": self._extract_memory_summary(product.get("memory", "") or ""),
                "lcd_summary": self._extract_lcd_summary(product.get("lcd", "") or ""),
                "battery_summary": self._extract_battery_summary(product.get("battery", "") or ""),
                "portability": self._assess_portability(product),
                "matched_features": feature_hits
            }
            summarized_products.append(summarized_product)
        
        return {
            "query": product_data.get("query", ""),
            "status": product_data.get("status", ""),
            "count": len(summarized_products),
            "products": summarized_products,
            "note": f"å·²æ‘˜è¦ç‚º {len(summarized_products)} å€‹ä¸»è¦ç”¢å“è¦æ ¼"
        }
    
    def _extract_cpu_summary(self, cpu_text: str) -> str:
        """æå– CPU é—œéµè³‡è¨Š"""
        if not cpu_text:
            return "æœªæä¾› CPU è³‡è¨Š"
        # æå–ä¸»è¦ CPU å‹è™Ÿå’Œç³»åˆ—
        cpu_lines = cpu_text.split('\n')
        for line in cpu_lines:
            if any(keyword in line for keyword in ['Ryzen', 'AMD']):
                return line.strip()[:100]  # é™åˆ¶é•·åº¦
        
        return cpu_text[:50] + "..." if len(cpu_text) > 50 else cpu_text
    
    def _extract_memory_summary(self, memory_text: str) -> str:
        """æå–è¨˜æ†¶é«”é—œéµè³‡è¨Š"""
        if not memory_text:
            return "æœªæä¾›è¨˜æ†¶é«”è³‡è¨Š"
        
        # å°‹æ‰¾è¨˜æ†¶é«”å®¹é‡å’Œé¡å‹
        import re
        ram_match = re.search(r'(\d+G[B]?|\d+GB|\d+TB)', memory_text)
        ddr_match = re.search(r'(DDR\d+|LPDDR\d+)', memory_text)
        
        summary_parts = []
        if ddr_match:
            summary_parts.append(ddr_match.group(1))
        if ram_match:
            summary_parts.append(f"æœ€é«˜ {ram_match.group(1)}")
        
        return " ".join(summary_parts) if summary_parts else memory_text[:50]
    
    def _extract_lcd_summary(self, lcd_text: str) -> str:
        """æå–è¢å¹•é—œéµè³‡è¨Š"""
        if not lcd_text:
            return "æœªæä¾›è¢å¹•è³‡è¨Š"
        
        # æå–è¢å¹•å°ºå¯¸å’Œè§£æåº¦
        import re
        size_match = re.search(r'(\d+\.?\d*)"', lcd_text)
        resolution_match = re.search(r'(\d+\*\d+|\d+x\d+)', lcd_text)
        
        summary_parts = []
        if size_match:
            summary_parts.append(f"{size_match.group(1)}å‹")
        if resolution_match:
            summary_parts.append(resolution_match.group(1))
        
        return " ".join(summary_parts) if summary_parts else lcd_text[:50]
    
    def _extract_battery_summary(self, battery_text: str) -> str:
        """æå–é›»æ± é—œéµè³‡è¨Š"""
        if not battery_text:
            return "æœªæä¾›é›»æ± è³‡è¨Š"
        
        # æå–é›»æ± å®¹é‡å’ŒçºŒèˆªåŠ›
        import re
        capacity_match = re.search(r'(\d+Wh)', battery_text)
        life_match = re.search(r'(\d+\s*[å°æ™‚|Hours|Hour])', battery_text)
        
        summary_parts = []
        if capacity_match:
            summary_parts.append(capacity_match.group(1))
        if life_match:
            summary_parts.append(f"çºŒèˆª {life_match.group(1)}")
        
        # æª¢æ¸¬ PD/å¿«å……ç­‰é—œéµå­—
        bt_lower = battery_text.lower()
        if any(k in bt_lower for k in ["pd", "power delivery", "å¿«å……", "fast charging", "fast charge"]):
            # å˜—è©¦æŠ“ PD ç‰ˆæœ¬
            pd_ver = None
            m = re.search(r'(pd\s*\d+(?:\.\d+)?)', bt_lower)
            if m:
                pd_ver = m.group(1).upper().replace(" ", "")
            summary_parts.append(f"æ”¯æ´ {pd_ver if pd_ver else 'PD'} å¿«å……")
        
        return " ".join(summary_parts) if summary_parts else "æ¨™æº–é›»æ± "
    
    def _assess_portability(self, product: Dict[str, Any]) -> str:
        """è©•ä¼°ä¾¿æ”œæ€§"""
        lcd = product.get("lcd", "") or ""  # ç¢ºä¿ä¸æ˜¯ None
        battery = product.get("battery", "") or ""  # ç¢ºä¿ä¸æ˜¯ None
        
        # ç°¡å–®çš„ä¾¿æ”œæ€§è©•ä¼°
        if any(size in lcd for size in ["11.6", "12", "13", "14"]):
            return "è¼•è–„ä¾¿æ”œ"
        elif any(size in lcd for size in ["15.6", "16"]):
            return "æ¨™æº–å°ºå¯¸"
        else:
            return "å°ºå¯¸æœªçŸ¥"
    
    # generate three-tier prompt
    # def generate_three_tier_prompt(self,product_data=None, user_query=None):
    async def generate_main_prompt(self,product_data=None, user_query=None):
        """ç”Ÿæˆä¸‰å±¤å¼æç¤º - ä¿®å¾©ç‰ˆï¼šé¿å…æ¨¡æ¿ç‹€æ…‹æ±¡æŸ“"""
        # ğŸ”§ ä¿®å¾©ï¼šæ¯æ¬¡éƒ½å¾ä¹¾æ·¨çš„æ¨¡æ¿é–‹å§‹ï¼Œé¿å…ç‹€æ…‹æ±¡æŸ“
        # ä½¿ç”¨ str.replace ä¾†é¿å… JSON ä¸­çš„ä½”ä½ç¬¦è¡çª
        query_rule_json = await self.get_query_rule_from_user_query(user_query=user_query)
        logger.info(f"^^^^^^^^^^^^^^^^^^^^^^^^^user_input_json start^^^^^^^^^^^^^^^^^^^^^^^^^\n")
        logger.info(f"åˆ†æuser input ä¸­çš„entities: {query_rule_json}")
        logger.info(f"\n^^^^^^^^^^^^^^^^^^^^^^^^^user_input_json end^^^^^^^^^^^^^^^^^^^^^^^^^")
        result = self.SysPromptTemplate.replace("{query_rules}", query_rule_json)
        result = result.replace("{user_query}", user_query)
        result = result.replace("{product_data}", str(product_data))
        # result = result.replace("{user_query}", str(user_query))
        return result
    
    async def get_query_rule_from_user_query(self, user_query: str) -> str:
        logger.info(f"^^^^^^^^^^^^^^^^^^^^^^^^^user_query start^^^^^^^^^^^^^^^^^^^^^^^^^\n")
        qry_str = await self.user_input_handler.getEntityParsingPrompt(user_query)
        self.query_rule = await asyncio.wait_for(
            asyncio.to_thread(self.llm_initializer.safe_completion, qry_str, 2048),
            timeout=120,
        )
        logger.info(f"åˆ†æuser input ä¸­çš„entities: {self.query_rule}")
        logger.info(f"\n^^^^^^^^^^^^^^^^^^^^^^^^^user_query end^^^^^^^^^^^^^^^^^^^^^^^^^")

        # Handle empty or invalid LLM responses
        if not self.query_rule or not self.query_rule.strip():
            logger.warning("LLMè¿”å›ç©ºéŸ¿æ‡‰ï¼Œä½¿ç”¨é è¨­æŸ¥è©¢è¦å‰‡")
            self.query_rule = '{"intent": "spec_check", "entities": [], "attributes": ["modelname"], "NB_NUM": "all", "language": "zh-TW"}'

        try:
            tmpdict = ast.literal_eval(self.query_rule)
            if tmpdict.get("NB_NUM") == "all":
                self.ComparableNB_NUM = 10
        except (ValueError, SyntaxError) as e:
            logger.error(f"è§£æLLMéŸ¿æ‡‰å¤±æ•—: {e}, éŸ¿æ‡‰å…§å®¹: {self.query_rule}")
            # Use fallback query rule
            self.query_rule = '{"intent": "spec_check", "entities": [], "attributes": ["modelname"], "NB_NUM": "all", "language": "zh-TW"}'
            tmpdict = ast.literal_eval(self.query_rule)
            if tmpdict.get("NB_NUM") == "all":
                self.ComparableNB_NUM = 10

        return self.query_rule
        
    
    def _load_welcome_prompt(self) -> str:
        welcome_prompt = """
            è§’è‰²ï¼šèº«ç‚ºä¸€åå°ˆæ¥­ä¸”è¦ªåˆ‡çš„ç­†è¨˜å‹é›»è…¦éŠ·å”®å°ˆå®¶ï¼Œä½ çš„ä»»å‹™æ˜¯ä¸»å‹•è¿æ¥é€²å…¥è³£å ´çš„å®¢æˆ¶ï¼Œä¸¦å¼•å°ä»–å€‘å®Œæˆä¸€æ®µæ„‰å¿«ä¸”æœ‰æ•ˆç‡çš„è³¼ç‰©é«”é©—ã€‚
            åŸå‰‡ï¼š
                1.å¾ç¾åœ¨èµ·ï¼Œè«‹ä½ ä¸»å‹•æå‡ºå•é¡Œç›´åˆ°ä½ æœ‰è¶³å¤ è³‡è¨Šèƒ½å¤ å›ç­”å®¢æˆ¶çš„å•é¡Œã€‚
            ä»»å‹™ï¼š
            1. ç”¨æº«æš–ä¸”é–‹æ”¾å¼çš„å•å€™é–‹å§‹å°è©±ï¼Œä¾‹å¦‚ï¼šã€Œæ‚¨å¥½ï¼Œæ­¡è¿å…‰è‡¨ï¼æƒ³æ‰¾ä¸€å°ä»€éº¼æ¨£çš„ç­†è¨˜å‹é›»è…¦å‘¢ï¼Ÿé‚„æ˜¯å…ˆéš¨æ„çœ‹çœ‹ï¼Ÿã€
            2. é¿å…çµ¦äºˆå£“åŠ›ï¼Œè®“å®¢æˆ¶æ„Ÿåˆ°è¼•é¬†è‡ªåœ¨ã€‚
            3. é€éç²¾æº–æå•ï¼Œåƒåµæ¢ä¸€æ¨£æ‹¼æ¹Šå‡ºå®¢æˆ¶çš„çœŸå¯¦éœ€æ±‚ã€‚
            4. æ ¹æ“šå®¢æˆ¶çš„éœ€æ±‚ï¼Œæå‡º 1-3 æ¬¾æœ€ç¬¦åˆçš„ç­†é›»é¸é …ã€‚
        """
        return welcome_prompt
    


    def _load_config(self) -> Dict[str, Any]:
        """è¼‰å…¥ç³»çµ±é…ç½®"""
        try:
            config_path = Path(__file__).parent / "config" / "system_config.json"
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                # ä½¿ç”¨é è¨­é…ç½®
                return {
                    "max_session_duration": 3600,  # 1å°æ™‚
                    "max_slots_per_session": 20,
                    "default_response_timeout": 30,
                    "enable_streaming": True,
                    "log_level": "INFO"
                }
        except Exception as e:
            logger.error(f"è¼‰å…¥é…ç½®å¤±æ•—: {e}")
            return {}
    
    def _load_state_machine(self) -> Dict[str, Dict[str, Any]]:
        """è¼‰å…¥ç‹€æ…‹æ©Ÿå®šç¾©"""
        try:
            state_machine = {
                "OnInit": {
                    "description": "ç‹€æ…‹æ©Ÿåˆå§‹åŒ–ç‹€æ…‹",
                    "actions": ["GenerateWelcomePrompt"],
                    "next_states": {
                        self.state_status.keyword_matched: "OnResponseMsg",
                        self.state_status.keyword_not_matched: "OnGenFunnelChat"
                    }
                },
                "OnReceiveMsg": {
                    "description": "æ¥æ”¶ç”¨æˆ¶æ¶ˆæ¯ç‹€æ…‹",
                    "actions": [
                        "ExtractKeyword",
                        "CompareSentence"
                    ],
                    "next_states": {
                        self.state_status.keyword_matched: "OnResponseMsg",
                        self.state_status.keyword_not_matched: "OnGenFunnelChat"
                    }
                },
                "OnResponseMsg": {
                    "description": "å›æ‡‰æ¶ˆæ¯ç‹€æ…‹",
                    "actions": [
                        "DataQuery",
                        "GenerateMDContent"
                    ],
                    "next_states": {
                        self.state_status.need_data_query: "OnDataQuery",
                        self.state_status.no_data_query: "OnGenFunnelChat"
                    }
                },
                "OnGenFunnelChat": {
                    "description": "ç”Ÿæˆæ¼æ–—å¼èŠå¤©ç‹€æ…‹",
                    "actions": [
                        "Generate Messages to guide customers to our product"
                    ],
                    "next_states": {
                        self.state_status.default: "OnGenMDContent"
                    }
                },
                "OnGenMDContent": {
                    "description": "ç”Ÿæˆ Markdown å…§å®¹ç‹€æ…‹",
                    "actions": [
                        "GenerateMDContent"
                    ],
                    "next_states": {
                        self.state_status.default: "OnGenMDContent"
                    }
                },
                "OnDataQuery": {
                    "description": "åŸ·è¡Œå…§éƒ¨æ•¸æ“šæŸ¥è©¢ç‹€æ…‹",
                    "actions": [
                        "DataQuery"
                    ],
                    "next_states": {
                        self.state_status.default: "OnQueriedDataProcessing"
                    }
                },
                "OnQueriedDataProcessing": {
                    "description": "æŸ¥è©¢æ•¸æ“šå¾Œè™•ç†ç‹€æ…‹",
                    "actions": [
                        "DataPostprocessing"
                    ],
                    "next_states": {
                        self.state_status.default: "OnSendFront"
                    }
                },
                "OnSendFront": {
                    "description": "ç™¼é€æ•¸æ“šåˆ°å‰ç«¯ç‹€æ…‹",
                    "actions": [
                        "SendDataToFront"
                    ],
                    "next_states": {
                        self.state_status.default: "OnWaitMsg"
                    }
                },
                "OnWaitMsg": {
                    "description": "ç­‰å¾…ä¸‹ä¸€æ¢æ¶ˆæ¯ç‹€æ…‹",
                    "actions": [
                        "WaitNextMessage"
                    ],
                    "next_states": {
                        self.state_status.default: "OnReceiveMsg"
                    }
                }
            }
            logger.info(f"æˆåŠŸè¼‰å…¥ç‹€æ…‹æ©Ÿå®šç¾©ï¼ŒåŒ…å« {len(state_machine)} å€‹ç‹€æ…‹")
            return state_machine
        except Exception as e:
            logger.error(f"è¼‰å…¥ç‹€æ…‹æ©Ÿå®šç¾©å¤±æ•—: {e}")
            return {}
    
    async def process_message(
        self, 
        session_id: str, 
        message: str, 
        stream: bool = False
    ) -> Dict[str, Any]:
        """
        è™•ç†ç”¨æˆ¶æ¶ˆæ¯ - ä¸»è¦å…¥å£é»
        
        Args:
            session_id: æœƒè©±è­˜åˆ¥ç¢¼
            message: ç”¨æˆ¶è¼¸å…¥æ¶ˆæ¯
            stream: æ˜¯å¦ä½¿ç”¨ä¸²æµå›æ‡‰
            
        Returns:
            åŒ…å«å›æ‡‰å…§å®¹çš„å­—å…¸ï¼Œæ ¼å¼å°é½Š mgfd_ai.js æœŸæœ›
        """
        try:
            logger.info(f"è™•ç†æ¶ˆæ¯ - æœƒè©±: {session_id}, æ¶ˆæ¯: {message}...")
            
            # æª¢æŸ¥æ¨¡çµ„æ˜¯å¦å·²åˆå§‹åŒ–
            if not self._check_modules_initialized():
                return self._create_error_response("ç³»çµ±æ¨¡çµ„æœªåˆå§‹åŒ–")
            
            # è™•ç†æ¶ˆæ¯
            result = await self._process_message_internal(session_id, message)
            
            # æ·»åŠ æœƒè©±IDåˆ°å›æ‡‰
            result['session_id'] = session_id
            result['timestamp'] = datetime.now().isoformat()
            
            logger.info(f"æ¶ˆæ¯è™•ç†å®Œæˆ - æœƒè©±: {session_id}")
            return result
            
        except Exception as e:
            logger.error(f"è™•ç†æ¶ˆæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return self._create_error_response(f"ç³»çµ±å…§éƒ¨éŒ¯èª¤: {str(e)}")
    
    
    async def get_session_state(self, session_id: str) -> Dict[str, Any]:
        """
        ç²å–æœƒè©±ç‹€æ…‹
        
        Args:
            session_id: æœƒè©±è­˜åˆ¥ç¢¼
            
        Returns:
            æœƒè©±ç‹€æ…‹å­—å…¸
        """
        try:
            if not self.state_manager:
                return self._create_error_response("ç‹€æ…‹ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            
            # æš«æ™‚è¿”å›åŸºæœ¬ç‹€æ…‹ï¼Œå¾… StateManagementHandler å¯¦ä½œ
            return {
                "success": True,
                "session_id": session_id,
                "current_stage": "unknown",
                "filled_slots": {},
                "chat_history": [],
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ç²å–æœƒè©±ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return self._create_error_response(f"ç²å–æœƒè©±ç‹€æ…‹å¤±æ•—: {str(e)}")
    
    async def reset_session(self, session_id: str) -> Dict[str, Any]:
        """
        é‡ç½®æœƒè©±
        
        Args:
            session_id: æœƒè©±è­˜åˆ¥ç¢¼
            
        Returns:
            é‡ç½®çµæœå­—å…¸
        """
        try:
            logger.info(f"é‡ç½®æœƒè©±: {session_id}")
            
            if not self.state_manager:
                return self._create_error_response("ç‹€æ…‹ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            
            # æš«æ™‚è¿”å›æˆåŠŸï¼Œå¾… StateManagementHandler å¯¦ä½œ
            return {
                "success": True,
                "session_id": session_id,
                "message": "LLM Responses",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"é‡ç½®æœƒè©±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return self._create_error_response(f"é‡ç½®æœƒè©±å¤±æ•—: {str(e)}")
    
    async def get_system_status(self) -> Dict[str, Any]:
        """
        ç²å–ç³»çµ±ç‹€æ…‹
        
        Returns:
            ç³»çµ±ç‹€æ…‹å­—å…¸
        """
        try:
            modules_status = {
                "user_input_handler": self.user_input_handler is not None,
                "prompt_manager": self.prompt_manager is not None,
                "knowledge_manager": self.knowledge_manager is not None,
                "response_generator": self.response_generator is not None,
                "state_manager": self.state_manager is not None
            }
            
            redis_status = "connected" if self.redis_client and self.redis_client.ping() else "disconnected"
            
            return {
                "success": True,
                "system_status": {
                    "redis": redis_status,
                    "modules": modules_status,
                    "timestamp": datetime.now().isoformat(),
                    "version": "v2.0.0"
                }
            }
            
        except Exception as e:
            logger.error(f"ç²å–ç³»çµ±ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return self._create_error_response(f"ç²å–ç³»çµ±ç‹€æ…‹å¤±æ•—: {str(e)}")
    
    

    """the kernel of the implementation of _processing user input"""
    async def _process_message_internal(
        self, 
        session_id: str, 
        message: str #user input message
    ) -> Dict[str, Any]:
        """
        å…§éƒ¨æ¶ˆæ¯è™•ç†æµç¨‹
        """
        # Step 1: å»ºç«‹ context
        context = {
            "session_id": session_id,
            "user_message": message,
            "keyword": "nodata",
            "product_data": {},
            "timestamp": datetime.now().isoformat(),
            "state": self.states.OnReceiveMsg,
            "slots": {},
            "query_result": {},
            "previous_answer": str,
            "history": [],
            "control": {},
            "errors": [],
            "slot_schema": self.slot_schema,
            "config": self.config
        }
        
        # Step 2: è§£æè¼¸å…¥ï¼ˆUserInputHandlerï¼‰
        # é è¨­å€¼ï¼Œé¿å…å¾ŒçºŒ NameErrorï¼KeyError
        slot_metadata = {}
        _product_data = {}
        if self.user_input_handler:
            slot_name, slot_metadata = await self.user_input_handler.parse_keyword(message)
            logger.info(f"***************************slot_name START*********************************: \né—œéµè©:\n{slot_name}")
        if slot_name:
            context.setdefault("slots", {}).update({slot_name: slot_metadata})
        else:
            context.setdefault("slots", {}).update({"": {}})
        
        # Step 3: ç‹€æ…‹æ©Ÿé©…å‹•ï¼ˆStateManagerï¼‰
        if slot_metadata.get("ifDBSearch", True):
            context["state"] = self.states.OnDataQuery#"OnDataQuery"#
        else:
            context["state"] = self.states.OnGenFunnelChat#"OnGenFunnelChat"
        self.query = message

        # Step 4: çŸ¥è­˜æŸ¥è©¢ï¼ˆå¦‚éœ€è¦ï¼‰
        #éœ€è¦åŠ å…¥knowledge_manager.search(context)
        #è‹¥ifDBSearchç‚ºTrueï¼Œå‰‡é€²è¡ŒçŸ¥è­˜æŸ¥è©¢ï¼Œä¸¦å°‡çµæœå­˜å…¥context["query_result"],
        #é€™æ˜¯product_data
        if slot_metadata.get("ifDBSearch", True):
            self.query_rule = await self.get_query_rule_from_user_query(message)
            logger.info(f"***************************slot_name START*********************************: \né—œéµè©:\n{self.query_rule}")
            logger.info(f"***************************slot_name START*********************************\n")
            # ç›´æ¥é€²è¡Œèˆ‡é—œéµå­—ç›¸é—œçš„ç”¢å“è¦æ ¼æœå°‹ï¼ˆä»¥éé˜»å¡æ–¹å¼åœ¨åŸ·è¡Œç·’æ± åŸ·è¡Œï¼‰
            _product_data = await asyncio.to_thread(self.knowledge_manager.search_product_data, message)
            context['keyword'] = slot_name
            logging.info(f"ç”¢å“æŸ¥è©¢çµæœ: {_product_data}")
            #é€²è¡Œ
        #step 5: generate three-tier prompt and send prompt to LLM
        # æ‘˜è¦ç”¢å“æ•¸æ“šä»¥å¤§å¹…æ¸›å°‘ Token æ¶ˆè€—
        if _product_data and isinstance(_product_data, dict) and _product_data.get("products"):
            logger.info(f"åŸå§‹ç”¢å“æ•¸æ“šåŒ…å« {len(_product_data.get('products', []))} å€‹ç”¢å“")
            # _summarize_product_dataåç¨±ä¸å¥½ï¼Œå› ç‚ºå…§éƒ¨åšäº†ä¸å°‘è™•ç†
            _product_data = self._postprocess_product_data(_product_data, max_products=self.ComparableNB_NUM)
            logger.info(f"æ‘˜è¦å¾Œç”¢å“æ•¸æ“šåŒ…å« {len(_product_data.get('products', []))} å€‹ç”¢å“")
        
        # å°‡ product_data è½‰ç‚º JSON å­—ä¸²æ³¨å…¥ï¼Œé™ä½æ¨¡å‹èª¤åˆ¤çµæ§‹æ©Ÿç‡
        product_data_json = json.dumps(_product_data, ensure_ascii=False, indent=2)
        logger.info(f"ç”¢å“è³‡æ–™ JSON é•·åº¦: {len(product_data_json)} (å·²å„ªåŒ–)")

        # ğŸ”§ ä¿®å¾©ï¼šä½¿ç”¨å±€éƒ¨è®Šé‡é¿å…ç‹€æ…‹æ±¡æŸ“
        # current_prompt = self.generate_three_tier_prompt(product_data=product_data_json, user_query=self.query)
        current_prompt = await self.generate_main_prompt(product_data=product_data_json, user_query=self.query)
        logger.info(f"***************************ç³»çµ±æç¤ºSTART********************************** \n{current_prompt}")
        logger.info(f"***************************ç³»çµ±æç¤ºEND***********************************\n")
        #_product_data
        # # å°‡ä½¿ç”¨è€…æŸ¥è©¢åŒæ™‚æä¾›ç‚º user_queryï¼Œé¿å…æ¨¡æ¿éµåä¸ä¸€è‡´å°è‡´ KeyError
        # 
        # self.SysPrompt = PromptTemplate(input_variables=["product_data", "user_query"], template=self.SysPrompt)
        # chain = self.SysPrompt | self.llm
        
        context['query_result'] = {"qry_result": _product_data}
        context['keyword'] = slot_name
        logging.info(f"product_data: {context['query_result']}")
        
        # Step 6: ç”Ÿæˆå›æ‡‰ï¼ˆResponseGeneratorï¼‰
        # è‹¥æŸ¥ç„¡ç”¢å“ï¼Œç›´æ¥å›è¦†æŒ‡å®šæç¤ºå¥ï¼›å¦å‰‡å°‡ System Prompt ç™¼é€çµ¦ LLM
        llm_output = None
        try:
            no_products = (
                isinstance(_product_data, dict)
                and (
                    _product_data.get("status") in {"no_results", "no_spec_data", "no_database", "error"}
                    or not _product_data.get("products")
                )
            )
            # tables = []
            if no_products:
                llm_output = "ç›®å‰å°šæœªæœå°‹åˆ°ç¬¦æ‚¨éœ€æ±‚çš„ç”¢å“ï¼Œæ˜¯å¦é€²è¡Œä¸åŒè¦æ ¼ç”¢å“çš„æœå°‹å‘¢ï¼Ÿ"
            else:
                if hasattr(self, 'llm_initializer') and self.llm_initializer:
                    try:
                        # ä½¿ç”¨ asyncio.wait_for æä¾›é¡å¤–çš„è¶…æ™‚ä¿è­·ï¼ˆ120ç§’ï¼Œç¨å¤§æ–¼ LLM çš„ request_timeoutï¼‰
                        llm_output = await asyncio.wait_for(
                            # asyncio.to_thread(self.llm.invoke, current_prompt),
                            asyncio.to_thread(self.llm_initializer.safe_completion, current_prompt,2048),
                            timeout=120
                        )
                        ## format markdown tables
                        # tables = self.extract_markdown_tables(llm_output)
                        # if tables:
                        #     for table in tables:
                        #         llm_output = llm_output.replace(table, f"```markdown\n{table}\n```")
                        ## end of format markdown tables
                        if isinstance(llm_output, dict):
                            llm_output = llm_output.get('content') or json.dumps(llm_output, ensure_ascii=False)
                        if llm_output is not None and not isinstance(llm_output, str):
                            llm_output = str(llm_output)
                        logger.info(f"LLM ç”ŸæˆæˆåŠŸï¼Œé•·åº¦: {len(llm_output) if llm_output else 0}")
                    except asyncio.TimeoutError:
                        logger.error("LLM èª¿ç”¨è¶…æ™‚ (120ç§’)ï¼Œå›é€€è‡³ç°¡åŒ–å›æ‡‰")
                        llm_output = "æŠ±æ­‰ï¼Œç³»çµ±è™•ç†æ™‚é–“è¼ƒé•·ï¼Œæˆ‘ç‚ºæ‚¨æä¾›ç°¡åŒ–çš„ç”¢å“å»ºè­°ã€‚æ ¹æ“šæ‚¨çš„éœ€æ±‚ã€Œè¼•ä¾¿å®¹æ˜“æ”œå¸¶ã€ï¼Œæˆ‘æ¨è–¦ä»¥ä¸‹è¼•è–„ç­†é›»é¡å‹ï¼Œè©³ç´°è¦æ ¼è«‹è¯ç¹«å®¢æœå°ˆå®¶ç²å¾—å”åŠ©ã€‚"
                    except Exception as e:
                        logger.error(f"LLM èª¿ç”¨ç™¼ç”Ÿç•°å¸¸: {e}")
                        llm_output = "ç³»çµ±æš«æ™‚ç„¡æ³•ç”Ÿæˆè©³ç´°å›æ‡‰ï¼Œå»ºè­°è¯ç¹«å®¢æœå°ˆå®¶ä»¥ç²å¾—ç”¢å“æ¨è–¦ã€‚"
                else:
                    logger.info("LLM æœªåˆå§‹åŒ–ï¼Œè·³éç”Ÿæˆæ­¥é©Ÿï¼Œå›é€€è‡³è³‡æ–™å­—ä¸²")
        except Exception as e:
            logger.warning(f"LLM ç”Ÿæˆå¤±æ•—ï¼Œå›é€€è‡³æŸ¥è©¢è³‡æ–™: {e}")

        # step 7: format frontend response
        # presentation_data_prompt = """
        # *æ¡ç”¨markdownæ ¼å¼è¼¸å‡ºï¼šè«‹markdown syntaxç”¢ç”Ÿå°ˆæ¥­ã€ç°¡æ½”ã€ç¾è§€çš„å ±å‘Šï¼Œè®“ä½¿ç”¨è€…èƒ½å¤ æ¸…æ¥šäº†è§£ã€‚
        # {product_data}
        # """.format(product_data=product_data_json)
        # è‹¥æœ‰ llm_output å‰‡å„ªå…ˆä½¿ç”¨ï¼Œå¦å‰‡å›å‚³æŸ¥è©¢è³‡æ–™å­—ä¸²ï¼Œé¿å…å‰ç«¯é¡¯ç¤º [object Object]
        
        response_result = {
            "type": "general",
            "message": llm_output,
            "success": True
        }
       
        return response_result
        
    
    def _format_frontend_response(
        self, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–å‰ç«¯å›æ‡‰
        
        Args:
            context: è™•ç†ä¸Šä¸‹æ–‡
            
        Returns:
            æ ¼å¼åŒ–å¾Œçš„å›æ‡‰å­—å…¸
        """
        state = context.get('state', 'unknown')
        response_type = context.get('response_type', 'general')
        
        # æ ¹æ“šç‹€æ…‹å’Œå›æ‡‰é¡å‹æ ¼å¼åŒ–
        if state == 'OnReceiveMsg':
            return {
                "success": True,
                "type": "funnel_start",
                "message": context.get('funnel_intro', 'æ­¡è¿ä½¿ç”¨ç­†é›»è³¼ç‰©åŠ©æ‰‹ï¼'),
                "session_id": context.get('session_id')
            }
        elif state == 'OnGenFunnelChat':
            return {
                "success": True,
                "type": "funnel_question",
                "question": {
                    "question_text": context.get('current_question'),
                    "options": context.get('question_options', [])
                },
                "session_id": context.get('session_id'),
                "message": context.get('question_message', '')
            }
        elif state == 'OnResponseMsg':
            return {
                "success": True,
                "type": "recommendation",
                "recommendations": context.get('recommendations', []),
                "comparison_table": context.get('comparison_table'),
                "summary": context.get('recommendation_summary'),
                "session_id": context.get('session_id')
            }
        elif state == 'OnGenMDContent':
            return {
                "success": True,
                "type": "elicitation",
                "message": context.get('elicitation_message'),
                "slots_needed": context.get('slots_needed', []),
                "session_id": context.get('session_id')
            }
        else:
            # ç›´æ¥è¿”å›çµæ§‹åŒ–æ ¼å¼ï¼Œä¸è¦åŒ…è£æˆ stream_response
            return {
                "success": True,
                "type": "general",
                "message": context.get('message') or context.get('response_message', ''),
                "session_id": context.get('session_id')
            }
    
    def _check_modules_initialized(self) -> bool:
        """æª¢æŸ¥æ¨¡çµ„æ˜¯å¦å·²åˆå§‹åŒ–"""
        # åªéœ€è¦ UserInputHandler å·²åˆå§‹åŒ–å³å¯é€²è¡ŒåŸºæœ¬è™•ç†
        return self.user_input_handler is not None
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """å‰µå»ºéŒ¯èª¤å›æ‡‰"""
        return {
            "success": False,
            "error": error_message,
            "timestamp": datetime.now().isoformat()
        }
    
    def set_user_input_handler(self, handler):
        """è¨­ç½®ç”¨æˆ¶è¼¸å…¥è™•ç†å™¨"""
        self.user_input_handler = handler
        logger.info("UserInputHandler å·²è¨­ç½®")
    
    def set_prompt_manager(self, manager):
        """è¨­ç½®æç¤ºç®¡ç†å™¨"""
        self.prompt_manager = manager
        logger.info("PromptManagementHandler å·²è¨­ç½®")
    
    def set_knowledge_manager(self, manager):
        """è¨­ç½®çŸ¥è­˜ç®¡ç†å™¨"""
        self.knowledge_manager = manager
        logger.info("KnowledgeManagementHandler å·²è¨­ç½®")
    
    def set_response_generator(self, generator):
        """è¨­ç½®å›æ‡‰ç”Ÿæˆå™¨"""
        self.response_generator = generator
        logger.info("ResponseGenHandler å·²è¨­ç½®")
    
    def set_state_manager(self, manager):
        """è¨­ç½®ç‹€æ…‹ç®¡ç†å™¨"""
        self.state_manager = manager
        logger.info("StateManagementHandler å·²è¨­ç½®")
